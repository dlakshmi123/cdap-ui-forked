<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta name="robots" content="noindex, nofollow">

    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <script type="text/javascript">

      var _gaq = _gaq || [];
      _gaq.push(['_setAccount', 'UA-55081520-2']);
      _gaq.push(['_trackPageview']);

      (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
      })();
    </script>
    <title>Cask Data Application Platform Programming Guide &mdash; Cask Data Application Platform 2.5.0 Documentation</title>
    
    <link rel="stylesheet" href="_static/cdap.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '2.5.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  false
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <link rel="shortcut icon" href="_static/favicon.ico"/>
    <link rel="top" title="Cask Data Application Platform 2.5.0 Documentation" href="index.html" />
    <link rel="next" title="Cask Data Application Platform Applications and Packs" href="apps-packs.html" />
    <link rel="prev" title="Cask Data Application Platform Concepts and Architecture" href="arch.html" /> 
  </head>
  <body role="document">
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">Index</a></li>
        <li class="right" >
          <a href="apps-packs.html" title="Cask Data Application Platform Applications and Packs"
             accesskey="N">Next</a> |</li>
        <li class="right" >
          <a href="arch.html" title="Cask Data Application Platform Concepts and Architecture"
             accesskey="P">Previous</a> |</li>
        <li><a href="index.html">Cask Data Application Platform 2.5.0 Documentation</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="cask-data-application-platform-programming-guide">
<h1>Cask Data Application Platform Programming Guide<a class="headerlink" href="#cask-data-application-platform-programming-guide" title="Permalink to this headline">¶</a></h1>
<div class="section" id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p>This document covers the two core virtualizations in the Cask Data Application Platform (CDAP) — Data and Applications.
Data virtualizations are grouped into streams and datasets. Application virtualizations are grouped into
Flows, MapReduce, Spark, Workflows, and Services. This document
details how to work with these abstractions to build Big Data applications.</p>
<p>For a high-level view of the concepts of the Cask Data Application Platform,
please see <a class="reference internal" href="arch.html"><em>Concepts and Architecture</em></a>.</p>
<p>For more information beyond this document, see the
<a class="reference internal" href="javadocs/index.html"><em>Javadocs</em></a> and the code in the
<a class="reference internal" href="getstarted.html#examples"><em>Examples</em></a> directory, both of which are on the
<a class="reference external" href="http://cask.co">Cask.co</a> <a class="reference external" href="http://cask.co/resources">resources page</a> as well as in your
CDAP installation directory.</p>
</div>
<div class="section" id="data-virtualization">
<h2>Data Virtualization<a class="headerlink" href="#data-virtualization" title="Permalink to this headline">¶</a></h2>
<p>There are two main data virtualizations: Streams and Datasets. Streams are ordered, partitioned
sequences of data, and are the primary means of bringing data from external systems into the CDAP
in realtime. Datasets are abstractions on top of data, allowing you to access your data using
higher-level abstractions and generic, reusable Java implementations of common data patterns
instead of requiring you to manipulate data with low-level APIs.</p>
</div>
<div class="section" id="streams">
<span id="id1"></span><h2>Streams<a class="headerlink" href="#streams" title="Permalink to this headline">¶</a></h2>
<p><strong>Streams</strong> are the primary means of bringing data from external systems into the CDAP in realtime.
They are ordered, time-partitioned sequences of data, usable for realtime collection and consumption of data.
You specify a Stream in your <a class="reference internal" href="#applications"><em>Application</em></a> specification:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="n">addStream</span><span class="o">(</span><span class="k">new</span> <span class="n">Stream</span><span class="o">(</span><span class="s">&quot;myStream&quot;</span><span class="o">));</span>
</pre></div>
</div>
<p>specifies a new Stream named <em>myStream</em>. Names used for Streams need to
be unique across the CDAP instance.</p>
<p>You can write to Streams either one operation at a time or in batches,
using either the <a class="reference internal" href="api.html#rest-streams"><em>Cask Data Application Platform HTTP RESTful API</em></a>
or command line tools.</p>
<p>Each individual signal sent to a Stream is stored as a <tt class="docutils literal"><span class="pre">StreamEvent</span></tt>,
which is comprised of a header (a map of strings for metadata) and a
body (a blob of arbitrary binary data).</p>
<p>Streams are uniquely identified by an ID string (a &#8220;name&#8221;) and are
explicitly created before being used. They can be created
programmatically within your application, through the CDAP Console,
or by or using a command line tool. Data written to a Stream
can be consumed in real-time by Flows or in batch by MapReduce. Streams are shared
between applications, so they require a unique name.</p>
</div>
<div class="section" id="datasets">
<span id="id2"></span><h2>Datasets<a class="headerlink" href="#datasets" title="Permalink to this headline">¶</a></h2>
<p><strong>Datasets</strong> store and retrieve data. Datasets are your means of reading
from and writing to the CDAP’s storage capabilities. Instead of
forcing you to manipulate data with low-level APIs, Datasets provide
higher-level abstractions and generic, reusable implementations of
common data patterns.</p>
<p>The core Dataset of the CDAP is a Table. Unlike relational database
systems, these tables are not organized into rows with a fixed schema.
They are optimized for efficient storage of semi-structured data, data
with unknown or variable schema, or sparse data.</p>
<p>Other Datasets are built on top of Tables. A Dataset can implement
specific semantics around a Table, such as a key/value Table or a
counter Table. A Dataset can also combine multiple Datasets to create a
complex data pattern. For example, an indexed Table can be implemented
by using one Table for the data and a second Table for the index of that data.</p>
<p>A number of useful Datasets—we refer to them as system Datasets—are
included with CDAP, including key/value tables, indexed tables and
time series. You can implement your own data patterns as custom
Datasets on top of Tables.</p>
<p>You can create a Dataset in CDAP using either the
<a class="reference internal" href="api.html#rest-datasets"><em>Cask Data Application Platform HTTP RESTful API</em></a> or command line tools.</p>
<p>You can also tell Applications to create a Dataset if it does not already
exist by declaring the Dataset details in the Application specification.
For example, to create a DataSet named <em>myCounters</em> of type
<a class="reference external" href="javadocs/co/cask/cdap/api/dataset/lib/KeyValueTable.html">KeyValueTable</a>, write:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="kd">public</span> <span class="kt">void</span> <span class="nf">configure</span><span class="o">()</span> <span class="o">{</span>
    <span class="n">createDataset</span><span class="o">(</span><span class="s">&quot;myCounters&quot;</span><span class="o">,</span> <span class="n">KeyValueTable</span><span class="o">.</span><span class="na">class</span><span class="o">);</span>
    <span class="o">...</span>
</pre></div>
</div>
<p>To use the Dataset in a Program, instruct the runtime
system to inject an instance of the Dataset with the <tt class="docutils literal"><span class="pre">&#64;UseDataSet</span></tt>
annotation:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="kd">class</span> <span class="nc">MyFlowlet</span> <span class="kd">extends</span> <span class="n">AbstractFlowlet</span> <span class="o">{</span>
  <span class="nd">@UseDataSet</span><span class="o">(</span><span class="s">&quot;myCounters&quot;</span><span class="o">)</span>
  <span class="kd">private</span> <span class="n">KeyValueTable</span> <span class="n">counters</span><span class="o">;</span>
  <span class="o">...</span>
  <span class="kt">void</span> <span class="nf">process</span><span class="o">(</span><span class="n">String</span> <span class="n">key</span><span class="o">)</span> <span class="o">{</span>
    <span class="n">counters</span><span class="o">.</span><span class="na">increment</span><span class="o">(</span><span class="n">key</span><span class="o">.</span><span class="na">getBytes</span><span class="o">(),</span> <span class="mi">1L</span><span class="o">);</span>
  <span class="o">}</span>
</pre></div>
</div>
<p>The runtime system reads the Dataset specification for the key/value
table <em>myCounters</em> from the metadata store and injects an
instance of the Dataset class into the Application.</p>
<p>You can also implement custom Datasets by implementing the <tt class="docutils literal"><span class="pre">Dataset</span></tt>
interface or by extending existing Dataset types. See the
<a class="reference internal" href="getstarted.html#purchase"><em>Purchase Example</em></a> for an implementation of a Custom Dataset.
For more details, refer to <a class="reference internal" href="#custom-datasets"><em>Custom Datasets</em></a></p>
<div class="section" id="types-of-datasets">
<h3>Types of Datasets<a class="headerlink" href="#types-of-datasets" title="Permalink to this headline">¶</a></h3>
<p>A Dataset abstraction is defined by a Java class that implements the <tt class="docutils literal"><span class="pre">DatasetDefinition</span></tt> interface.
The implementation of a Dataset typically relies on one or more underlying (embedded) Datasets.
For example, the <tt class="docutils literal"><span class="pre">IndexedTable</span></tt> Dataset can be implemented by two underlying Table Datasets –
one holding the data and one holding the index.</p>
<p>We distinguish three categories of Datasets: <em>core</em>, <em>system</em>, and <em>custom</em> Datasets:</p>
<ul class="simple">
<li>The <strong>core</strong> Dataset of the CDAP is a Table. Its implementation may use internal
CDAP classes hidden from developers.</li>
<li>A <strong>system</strong> Dataset is bundled with the CDAP and is built around
one or more underlying core or system Datasets to implement a specific data pattern.</li>
<li>A <strong>custom</strong> Dataset is implemented by you and can have arbitrary code and methods.
It is typically built around one or more Tables (or other Datasets)
to implement a specific data pattern.</li>
</ul>
<p>Each Dataset is associated with exactly one Dataset implementation to
manipulate it. Every Dataset has a unique name and metadata that defines its behavior.
For example, every <tt class="docutils literal"><span class="pre">IndexedTable</span></tt> has a name and indexes a particular column of its primary table:
the name of that column is a metadata property of each Dataset of this type.</p>
</div>
<div class="section" id="core-datasets">
<h3>Core Datasets<a class="headerlink" href="#core-datasets" title="Permalink to this headline">¶</a></h3>
<p><strong>Tables</strong> are the only core Datasets, and all other Datasets are built using one or more
Tables. These Tables are similar to tables in a relational database with a few key differences:</p>
<ul class="simple">
<li>Tables have no fixed schema. Unlike relational database tables where every
row has the same schema, every row of a Table can have a different set of columns.</li>
<li>Because the set of columns is not known ahead of time, the columns of
a row do not have a rich type. All column values are byte arrays and
it is up to the application to convert them to and from rich types.
The column names and the row key are also byte arrays.</li>
<li>When reading from a Table, one need not know the names of the columns:
The read operation returns a map from column name to column value.
It is, however, possible to specify exactly which columns to read.</li>
<li>Tables are organized in a way that the columns of a row can be read
and written independently of other columns, and columns are ordered
in byte-lexicographic order. They are also known as <em>Ordered Columnar Tables</em>.</li>
</ul>
</div>
<div class="section" id="table-api">
<h3>Table API<a class="headerlink" href="#table-api" title="Permalink to this headline">¶</a></h3>
<p>The <tt class="docutils literal"><span class="pre">Table</span></tt> API provides basic methods to perform read, write and delete operations,
plus special scan, atomic increment and compare-and-swap operations:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="c1">// Read</span>
<span class="kd">public</span> <span class="n">Row</span> <span class="nf">get</span><span class="o">(</span><span class="n">Get</span> <span class="n">get</span><span class="o">)</span>
<span class="kd">public</span> <span class="n">Row</span> <span class="nf">get</span><span class="o">(</span><span class="kt">byte</span><span class="o">[]</span> <span class="n">row</span><span class="o">)</span>
<span class="kd">public</span> <span class="kt">byte</span><span class="o">[]</span> <span class="nf">get</span><span class="o">(</span><span class="kt">byte</span><span class="o">[]</span> <span class="n">row</span><span class="o">,</span> <span class="kt">byte</span><span class="o">[]</span> <span class="n">column</span><span class="o">)</span>
<span class="kd">public</span> <span class="n">Row</span> <span class="nf">get</span><span class="o">(</span><span class="kt">byte</span><span class="o">[]</span> <span class="n">row</span><span class="o">,</span> <span class="kt">byte</span><span class="o">[][]</span> <span class="n">columns</span><span class="o">)</span>
<span class="kd">public</span> <span class="n">Row</span> <span class="nf">get</span><span class="o">(</span><span class="kt">byte</span><span class="o">[]</span> <span class="n">row</span><span class="o">,</span> <span class="kt">byte</span><span class="o">[]</span> <span class="n">startColumn</span><span class="o">,</span>
               <span class="kt">byte</span><span class="o">[]</span> <span class="n">stopColumn</span><span class="o">,</span> <span class="kt">int</span> <span class="n">limit</span><span class="o">)</span>

<span class="c1">// Scan</span>
<span class="kd">public</span> <span class="n">Scanner</span> <span class="nf">scan</span><span class="o">(</span><span class="kt">byte</span><span class="o">[]</span> <span class="n">startRow</span><span class="o">,</span> <span class="kt">byte</span><span class="o">[]</span> <span class="n">stopRow</span><span class="o">)</span>

<span class="c1">// Write</span>
<span class="kd">public</span> <span class="kt">void</span> <span class="nf">put</span><span class="o">(</span><span class="n">Put</span> <span class="n">put</span><span class="o">)</span>
<span class="kd">public</span> <span class="kt">void</span> <span class="nf">put</span><span class="o">(</span><span class="kt">byte</span><span class="o">[]</span> <span class="n">row</span><span class="o">,</span> <span class="kt">byte</span><span class="o">[]</span> <span class="n">column</span><span class="o">,</span> <span class="kt">byte</span><span class="o">[]</span> <span class="n">value</span><span class="o">)</span>
<span class="kd">public</span> <span class="kt">void</span> <span class="nf">put</span><span class="o">(</span><span class="kt">byte</span><span class="o">[]</span> <span class="n">row</span><span class="o">,</span> <span class="kt">byte</span><span class="o">[][]</span> <span class="n">columns</span><span class="o">,</span> <span class="kt">byte</span><span class="o">[][]</span> <span class="n">values</span><span class="o">)</span>

<span class="c1">// Compare And Swap</span>
<span class="kd">public</span> <span class="kt">boolean</span> <span class="nf">compareAndSwap</span><span class="o">(</span><span class="kt">byte</span><span class="o">[]</span> <span class="n">row</span><span class="o">,</span> <span class="kt">byte</span><span class="o">[]</span> <span class="n">column</span><span class="o">,</span>
                              <span class="kt">byte</span><span class="o">[]</span> <span class="n">expectedValue</span><span class="o">,</span> <span class="kt">byte</span><span class="o">[]</span> <span class="n">newValue</span><span class="o">)</span>

<span class="c1">// Increment and return result</span>
<span class="kd">public</span> <span class="n">Row</span> <span class="nf">incrementAndGet</span><span class="o">(</span><span class="n">Increment</span> <span class="n">increment</span><span class="o">)</span>
<span class="kd">public</span> <span class="kt">long</span> <span class="nf">incrementAndGet</span><span class="o">(</span><span class="kt">byte</span><span class="o">[]</span> <span class="n">row</span><span class="o">,</span> <span class="kt">byte</span><span class="o">[]</span> <span class="n">column</span><span class="o">,</span> <span class="kt">long</span> <span class="n">amount</span><span class="o">)</span>
<span class="kd">public</span> <span class="n">Row</span> <span class="nf">incrementAndGet</span><span class="o">(</span><span class="kt">byte</span><span class="o">[]</span> <span class="n">row</span><span class="o">,</span> <span class="kt">byte</span><span class="o">[][]</span> <span class="n">columns</span><span class="o">,</span> <span class="kt">long</span><span class="o">[]</span> <span class="n">amounts</span><span class="o">)</span>

<span class="c1">// Increment without result</span>
<span class="kd">public</span> <span class="kt">void</span> <span class="nf">increment</span><span class="o">(</span><span class="n">Increment</span> <span class="n">increment</span><span class="o">)</span>
<span class="kd">public</span> <span class="kt">void</span> <span class="nf">increment</span><span class="o">(</span><span class="kt">byte</span><span class="o">[]</span> <span class="n">row</span><span class="o">,</span> <span class="kt">byte</span><span class="o">[]</span> <span class="n">column</span><span class="o">,</span> <span class="kt">long</span> <span class="n">amount</span><span class="o">)</span>
<span class="kd">public</span> <span class="kt">void</span> <span class="nf">increment</span><span class="o">(</span><span class="kt">byte</span><span class="o">[]</span> <span class="n">row</span><span class="o">,</span> <span class="kt">byte</span><span class="o">[][]</span> <span class="n">columns</span><span class="o">,</span> <span class="kt">long</span><span class="o">[]</span> <span class="n">amounts</span><span class="o">)</span>

<span class="c1">// Delete</span>
<span class="kd">public</span> <span class="kt">void</span> <span class="nf">delete</span><span class="o">(</span><span class="n">Delete</span> <span class="n">delete</span><span class="o">)</span>
<span class="kd">public</span> <span class="kt">void</span> <span class="nf">delete</span><span class="o">(</span><span class="kt">byte</span><span class="o">[]</span> <span class="n">row</span><span class="o">)</span>
<span class="kd">public</span> <span class="kt">void</span> <span class="nf">delete</span><span class="o">(</span><span class="kt">byte</span><span class="o">[]</span> <span class="n">row</span><span class="o">,</span> <span class="kt">byte</span><span class="o">[]</span> <span class="n">column</span><span class="o">)</span>
<span class="kd">public</span> <span class="kt">void</span> <span class="nf">delete</span><span class="o">(</span><span class="kt">byte</span><span class="o">[]</span> <span class="n">row</span><span class="o">,</span> <span class="kt">byte</span><span class="o">[][]</span> <span class="n">columns</span><span class="o">)</span>
</pre></div>
</div>
<p>Each basic operation has a method that takes an operation-type object as a parameter
plus handy methods for working directly with byte arrays.
If your application code already deals with byte arrays, you can use the latter methods to save a conversion.</p>
<div class="section" id="read">
<h4>Read<a class="headerlink" href="#read" title="Permalink to this headline">¶</a></h4>
<p>A <tt class="docutils literal"><span class="pre">get</span></tt> operation reads all columns or a selection of columns of a single row:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="n">Table</span> <span class="n">t</span><span class="o">;</span>
<span class="kt">byte</span><span class="o">[]</span> <span class="n">rowKey1</span><span class="o">;</span>
<span class="kt">byte</span><span class="o">[]</span> <span class="n">columnX</span><span class="o">;</span>
<span class="kt">byte</span><span class="o">[]</span> <span class="n">columnY</span><span class="o">;</span>
<span class="kt">int</span> <span class="n">n</span><span class="o">;</span>

<span class="c1">// Read all columns of a row</span>
<span class="n">Row</span> <span class="n">row</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="na">get</span><span class="o">(</span><span class="k">new</span> <span class="n">Get</span><span class="o">(</span><span class="s">&quot;rowKey1&quot;</span><span class="o">));</span>

<span class="c1">// Read specified columns from a row</span>
<span class="n">Row</span> <span class="n">rowSelection</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="na">get</span><span class="o">(</span><span class="k">new</span> <span class="n">Get</span><span class="o">(</span><span class="s">&quot;rowKey1&quot;</span><span class="o">).</span><span class="na">add</span><span class="o">(</span><span class="s">&quot;column1&quot;</span><span class="o">).</span><span class="na">add</span><span class="o">(</span><span class="s">&quot;column2&quot;</span><span class="o">));</span>

<span class="c1">// Reads a column range from x (inclusive) to y (exclusive)</span>
<span class="c1">// with a limit of n return values</span>
<span class="n">rowSelection</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="na">get</span><span class="o">(</span><span class="n">rowKey1</span><span class="o">,</span> <span class="n">columnX</span><span class="o">,</span> <span class="n">columnY</span><span class="o">;</span> <span class="n">n</span><span class="o">);</span>

<span class="c1">// Read only one column in one row byte[]</span>
<span class="n">value</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="na">get</span><span class="o">(</span><span class="n">rowKey1</span><span class="o">,</span> <span class="n">columnX</span><span class="o">);</span>
</pre></div>
</div>
<p>The <tt class="docutils literal"><span class="pre">Row</span></tt> object provides access to the row data including its columns. If only a
selection of row columns is requested, the returned <tt class="docutils literal"><span class="pre">Row</span></tt> object will contain only these columns.
The <tt class="docutils literal"><span class="pre">Row</span></tt> object provides an extensive API for accessing returned column values:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="c1">// Get column value as a byte array</span>
<span class="kt">byte</span><span class="o">[]</span> <span class="n">value</span> <span class="o">=</span> <span class="n">row</span><span class="o">.</span><span class="na">get</span><span class="o">(</span><span class="s">&quot;column1&quot;</span><span class="o">);</span>

<span class="c1">// Get column value of a specific type</span>
<span class="n">String</span> <span class="n">valueAsString</span> <span class="o">=</span> <span class="n">row</span><span class="o">.</span><span class="na">getString</span><span class="o">(</span><span class="s">&quot;column1&quot;</span><span class="o">);</span>
<span class="n">Integer</span> <span class="n">valueAsInteger</span> <span class="o">=</span> <span class="n">row</span><span class="o">.</span><span class="na">getInt</span><span class="o">(</span><span class="s">&quot;column1&quot;</span><span class="o">);</span>
</pre></div>
</div>
<p>When requested, the value of a column is converted to a specific type automatically.
If the column is absent in a row, the returned value is <tt class="docutils literal"><span class="pre">null</span></tt>. To return primitive types,
the corresponding methods accept a default value to be returned when the column is absent:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="c1">// Get column value as a primitive type or 0 if column is absent</span>
<span class="kt">long</span> <span class="n">valueAsLong</span> <span class="o">=</span> <span class="n">row</span><span class="o">.</span><span class="na">getLong</span><span class="o">(</span><span class="s">&quot;column1&quot;</span><span class="o">,</span> <span class="mi">0</span><span class="o">);</span>
</pre></div>
</div>
</div>
<div class="section" id="scan">
<h4>Scan<a class="headerlink" href="#scan" title="Permalink to this headline">¶</a></h4>
<p>A <tt class="docutils literal"><span class="pre">scan</span></tt> operation fetches a subset of rows or all of the rows of a Table:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="kt">byte</span><span class="o">[]</span> <span class="n">startRow</span><span class="o">;</span>
<span class="kt">byte</span><span class="o">[]</span> <span class="n">stopRow</span><span class="o">;</span>
<span class="n">Row</span> <span class="n">row</span><span class="o">;</span>

<span class="c1">// Scan all rows from startRow (inclusive) to</span>
<span class="c1">// stopRow (exclusive)</span>
<span class="n">Scanner</span> <span class="n">scanner</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="na">scan</span><span class="o">(</span><span class="n">startRow</span><span class="o">,</span> <span class="n">stopRow</span><span class="o">);</span>
<span class="k">try</span> <span class="o">{</span>
  <span class="k">while</span> <span class="o">((</span><span class="n">row</span> <span class="o">=</span> <span class="n">scanner</span><span class="o">.</span><span class="na">next</span><span class="o">())</span> <span class="o">!=</span> <span class="kc">null</span><span class="o">)</span> <span class="o">{</span>
    <span class="n">LOG</span><span class="o">.</span><span class="na">info</span><span class="o">(</span><span class="s">&quot;column1: &quot;</span> <span class="o">+</span> <span class="n">row</span><span class="o">.</span><span class="na">getString</span><span class="o">(</span><span class="s">&quot;column1&quot;</span><span class="o">,</span> <span class="s">&quot;null&quot;</span><span class="o">));</span>
  <span class="o">}</span>
<span class="o">}</span> <span class="k">finally</span> <span class="o">{</span>
  <span class="n">scanner</span><span class="o">.</span><span class="na">close</span><span class="o">();</span>
<span class="o">}</span>
</pre></div>
</div>
<p>To scan a set of rows not bounded by <tt class="docutils literal"><span class="pre">startRow</span></tt> and/or <tt class="docutils literal"><span class="pre">stopRow</span></tt>
you can pass <tt class="docutils literal"><span class="pre">null</span></tt> as their value:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="kt">byte</span><span class="o">[]</span> <span class="n">startRow</span><span class="o">;</span>
<span class="c1">// Scan all rows of a table</span>
<span class="n">Scanner</span> <span class="n">allRows</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="na">scan</span><span class="o">(</span><span class="kc">null</span><span class="o">,</span> <span class="kc">null</span><span class="o">);</span>
<span class="c1">// Scan all columns up to stopRow (exclusive)</span>
<span class="n">Scanner</span> <span class="n">headRows</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="na">scan</span><span class="o">(</span><span class="kc">null</span><span class="o">,</span> <span class="n">stopRow</span><span class="o">);</span>
<span class="c1">// Scan all columns starting from startRow (inclusive)</span>
<span class="n">Scanner</span> <span class="n">tailRows</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="na">scan</span><span class="o">(</span><span class="n">startRow</span><span class="o">,</span> <span class="kc">null</span><span class="o">);</span>
</pre></div>
</div>
</div>
<div class="section" id="write">
<h4>Write<a class="headerlink" href="#write" title="Permalink to this headline">¶</a></h4>
<p>A <tt class="docutils literal"><span class="pre">put</span></tt> operation writes data into a row:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="c1">// Write a set of columns with their values</span>
<span class="n">t</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="k">new</span> <span class="n">Put</span><span class="o">(</span><span class="s">&quot;rowKey1&quot;</span><span class="o">).</span><span class="na">add</span><span class="o">(</span><span class="s">&quot;column1&quot;</span><span class="o">,</span> <span class="s">&quot;value1&quot;</span><span class="o">).</span><span class="na">add</span><span class="o">(</span><span class="s">&quot;column2&quot;</span><span class="o">,</span> <span class="mi">55L</span><span class="o">));</span>
</pre></div>
</div>
</div>
<div class="section" id="compare-and-swap">
<h4>Compare and Swap<a class="headerlink" href="#compare-and-swap" title="Permalink to this headline">¶</a></h4>
<p>A swap operation compares the existing value of a column with an expected value,
and if it matches, replaces it with a new value.
The operation returns <tt class="docutils literal"><span class="pre">true</span></tt> if it succeeds and <tt class="docutils literal"><span class="pre">false</span></tt> otherwise:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="kt">byte</span><span class="o">[]</span> <span class="n">expectedCurrentValue</span><span class="o">;</span>
<span class="kt">byte</span><span class="o">[]</span> <span class="n">newValue</span><span class="o">;</span>
<span class="k">if</span> <span class="o">(!</span><span class="n">t</span><span class="o">.</span><span class="na">compareAndSwap</span><span class="o">(</span><span class="n">rowKey1</span><span class="o">,</span> <span class="n">columnX</span><span class="o">,</span>
      <span class="n">expectedCurrentValue</span><span class="o">,</span> <span class="n">newValue</span><span class="o">))</span> <span class="o">{</span>
  <span class="n">LOG</span><span class="o">.</span><span class="na">info</span><span class="o">(</span><span class="s">&quot;Current value was different from expected&quot;</span><span class="o">);</span>
<span class="o">}</span>
</pre></div>
</div>
</div>
<div class="section" id="increment">
<h4>Increment<a class="headerlink" href="#increment" title="Permalink to this headline">¶</a></h4>
<p>An increment operation increments a <tt class="docutils literal"><span class="pre">long</span></tt> value of one or more columns by either <tt class="docutils literal"><span class="pre">1L</span></tt>
or an integer amount <em>n</em>.  If a column does not exist, it is created with an assumed value of zero
before the increment is applied:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="c1">// Write long value to a column of a row</span>
<span class="n">t</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="k">new</span> <span class="n">Put</span><span class="o">(</span><span class="s">&quot;rowKey1&quot;</span><span class="o">).</span><span class="na">add</span><span class="o">(</span><span class="s">&quot;column1&quot;</span><span class="o">,</span> <span class="mi">55L</span><span class="o">));</span>
<span class="c1">// Increment values of several columns in a row</span>
<span class="n">t</span><span class="o">.</span><span class="na">increment</span><span class="o">(</span><span class="k">new</span> <span class="n">Increment</span><span class="o">(</span><span class="s">&quot;rowKey1&quot;</span><span class="o">).</span><span class="na">add</span><span class="o">(</span><span class="s">&quot;column1&quot;</span><span class="o">,</span> <span class="mi">1L</span><span class="o">).</span><span class="na">add</span><span class="o">(</span><span class="s">&quot;column2&quot;</span><span class="o">,</span> <span class="mi">23L</span><span class="o">));</span>
</pre></div>
</div>
<p>If the existing value of the column cannot be converted to a <tt class="docutils literal"><span class="pre">long</span></tt>,
a <tt class="docutils literal"><span class="pre">NumberFormatException</span></tt> will be thrown.</p>
<p>Two types of increment operations are supported:</p>
<ul class="simple">
<li><tt class="docutils literal"><span class="pre">incrementAndGet(...)</span></tt> operations will increment the currently stored value and return the
result; and</li>
<li><tt class="docutils literal"><span class="pre">increment(...)</span></tt> operations will increment the currently stored value without any return
value.</li>
</ul>
<p><em>Read-less Increments</em></p>
<p>By default, an increment operation will need to first perform a read operation to find the
currently stored column value, apply the increment to the stored value, and then write the final
result.  For high write volume workloads, with only occassional reads, this can impose a great
deal of unnecessary overhead for increments.</p>
<p>In these situations, you can configure the dataset to support read-less increments.  With read-less
increments, each operation only performs a write operation, storing the incremental value for the
column in a new cell.  This completely eliminates the cost of the read operation when performing
increments.  Instead, when reading the value for a column storing data for read-less increments,
all of the stored increment values are read and summed up together with the last stored complete
sum, in order to compute the final result.  As a result, read operations become more expensive, but
this trade-off can be very beneficial for workloads dominated by writes.</p>
<p>Read-less increments can only be used with the <tt class="docutils literal"><span class="pre">increment(...)</span></tt> operation, since it does not
return a value.  To configure a dataset to support read-less increments:</p>
<ol class="arabic simple">
<li>Set the property <tt class="docutils literal"><span class="pre">dataset.table.readless.increment</span></tt> to <tt class="docutils literal"><span class="pre">true</span></tt> in the DatasetSpecification
properties.</li>
<li>Use the <tt class="docutils literal"><span class="pre">increment(...)</span></tt> methods for any operations that do not need the result value of the
increment operation.</li>
</ol>
<p><em>Note:</em> the current implementation of read-less increments uses an HBase coprocessor to prefix the
stored values for incremental updates with a special prefix.  Since this prefix could occur
naturally in other stored data values, it is highly recommended that increments be stored in a
separate dataset and not be mixed in with other types of values.  This will ensure that other data is
not mis-identified as a stored increment and prevent incorrect results.</p>
</div>
<div class="section" id="delete">
<h4>Delete<a class="headerlink" href="#delete" title="Permalink to this headline">¶</a></h4>
<p>A delete operation removes an entire row or a subset of its columns:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="c1">// Delete the entire row</span>
<span class="n">t</span><span class="o">.</span><span class="na">delete</span><span class="o">(</span><span class="k">new</span> <span class="n">Delete</span><span class="o">(</span><span class="s">&quot;rowKey1&quot;</span><span class="o">));</span>
<span class="c1">// Delete a selection of columns from the row</span>
<span class="n">t</span><span class="o">.</span><span class="na">delete</span><span class="o">(</span><span class="k">new</span> <span class="n">Delete</span><span class="o">(</span><span class="s">&quot;rowKey1&quot;</span><span class="o">).</span><span class="na">add</span><span class="o">(</span><span class="s">&quot;column1&quot;</span><span class="o">).</span><span class="na">add</span><span class="o">(</span><span class="s">&quot;column2&quot;</span><span class="o">));</span>
</pre></div>
</div>
<p>Note that specifying a set of columns helps to perform delete operation faster.
When you want to delete all the columns of a row and you know all of them,
passing all of them will make the deletion faster.</p>
</div>
</div>
<div class="section" id="system-datasets">
<h3>System Datasets<a class="headerlink" href="#system-datasets" title="Permalink to this headline">¶</a></h3>
<p>The Cask Data Application Platform comes with several system-defined Datasets, including but not limited to
key/value Tables, indexed Tables and time series. Each of them is defined with the help of one or more embedded
Tables, but defines its own interface. Examples include:</p>
<ul class="simple">
<li>The <tt class="docutils literal"><span class="pre">KeyValueTable</span></tt> implements a key/value store as a Table with a single column.</li>
<li>The <tt class="docutils literal"><span class="pre">IndexedTable</span></tt> implements a Table with a secondary key using two embedded Tables,
one for the data and one for the secondary index.</li>
<li>The <tt class="docutils literal"><span class="pre">TimeseriesTable</span></tt> uses a Table to store keyed data over time
and allows querying that data over ranges of time.</li>
</ul>
<p>See the <a class="reference internal" href="javadocs/index.html"><em>Javadocs</em></a> for these classes and the <a class="reference internal" href="getstarted.html#examples"><em>Examples</em></a>
to learn more about these Datasets. Any class in the CDAP libraries that implements the <tt class="docutils literal"><span class="pre">Dataset</span></tt> interface is a
system Dataset.</p>
</div>
<div class="section" id="custom-datasets">
<span id="id3"></span><h3>Custom Datasets<a class="headerlink" href="#custom-datasets" title="Permalink to this headline">¶</a></h3>
<p>You can define your own Dataset classes to implement common data patterns specific to your code.</p>
<p>Suppose you want to define a counter table that, in addition to counting words,
counts how many unique words it has seen. The Dataset can be built on top of two underlying Datasets. The first a
Table (<tt class="docutils literal"><span class="pre">entryCountTable</span></tt>) to count all the words and the second a Table (<tt class="docutils literal"><span class="pre">uniqueCountTable</span></tt>) for the unique count.</p>
<p>When your custom Dataset is built on top of one or more existing Datasets, the simplest way to implement
it is to just define the data operations (by implementing the Dataset interface) and delegating all other
work (such as  administrative operations) to the embedded Dataset.</p>
<p>To do this, you need to implement the Dataset class and define the embedded Datasets by annotating
its constructor arguments.</p>
<p>In this case, our  <tt class="docutils literal"><span class="pre">UniqueCountTableDefinition</span></tt> will have two underlying Datasets:
an <tt class="docutils literal"><span class="pre">entryCountTable</span></tt> and an <tt class="docutils literal"><span class="pre">uniqueCountTable</span></tt>, both of type <tt class="docutils literal"><span class="pre">Table</span></tt>:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="kd">public</span> <span class="kd">class</span> <span class="nc">UniqueCountTable</span> <span class="kd">extends</span> <span class="n">AbstractDataset</span> <span class="o">{</span>

  <span class="kd">private</span> <span class="kd">final</span> <span class="n">Table</span> <span class="n">entryCountTable</span><span class="o">;</span>
  <span class="kd">private</span> <span class="kd">final</span> <span class="n">Table</span> <span class="n">uniqueCountTable</span><span class="o">;</span>

  <span class="kd">public</span> <span class="nf">UniqueCountTable</span><span class="o">(</span><span class="n">DatasetSpecification</span> <span class="n">spec</span><span class="o">,</span>
                          <span class="nd">@EmbeddedDataset</span><span class="o">(</span><span class="s">&quot;entryCountTable&quot;</span><span class="o">)</span> <span class="n">Table</span> <span class="n">entryCountTable</span><span class="o">,</span>
                          <span class="nd">@EmbeddedDataset</span><span class="o">(</span><span class="s">&quot;uniqueCountTable&quot;</span><span class="o">)</span> <span class="n">Table</span> <span class="n">uniqueCountTable</span><span class="o">)</span> <span class="o">{</span>
    <span class="kd">super</span><span class="o">(</span><span class="n">spec</span><span class="o">.</span><span class="na">getName</span><span class="o">(),</span> <span class="n">entryCountTable</span><span class="o">,</span> <span class="n">uniqueCountTable</span><span class="o">);</span>
    <span class="k">this</span><span class="o">.</span><span class="na">entryCountTable</span> <span class="o">=</span> <span class="n">entryCountTable</span><span class="o">;</span>
    <span class="k">this</span><span class="o">.</span><span class="na">uniqueCountTable</span> <span class="o">=</span> <span class="n">uniqueCountTable</span><span class="o">;</span>
  <span class="o">}</span>
</pre></div>
</div>
<p>In this case, the class must have one constructor that takes a <tt class="docutils literal"><span class="pre">DatasetSpecification</span></tt> as a first
parameter and any number of <tt class="docutils literal"><span class="pre">Dataset</span></tt>s annotated with the <tt class="docutils literal"><span class="pre">&#64;EmbeddedDataset</span></tt> annotation as the
remaining parameters. <tt class="docutils literal"><span class="pre">&#64;EmbeddedDataset</span></tt> takes the embedded Dataset&#8217;s name as a parameter.</p>
<p>The <tt class="docutils literal"><span class="pre">UniqueCountTable</span></tt> stores a counter for each word in its own row of the entry count table.
For each word the counter is incremented. If the result of the increment is 1, then this is the first time
we&#8217;ve encountered that word, hence we have a new unique word and we then increment the unique counter:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="kd">public</span> <span class="kt">void</span> <span class="nf">updateUniqueCount</span><span class="o">(</span><span class="n">String</span> <span class="n">entry</span><span class="o">)</span> <span class="o">{</span>
  <span class="kt">long</span> <span class="n">newCount</span> <span class="o">=</span> <span class="n">entryCountTable</span><span class="o">.</span><span class="na">incrementAndGet</span><span class="o">(</span><span class="k">new</span> <span class="n">Increment</span><span class="o">(</span><span class="n">entry</span><span class="o">,</span> <span class="s">&quot;count&quot;</span><span class="o">,</span> <span class="mi">1L</span><span class="o">)).</span><span class="na">getInt</span><span class="o">(</span><span class="s">&quot;count&quot;</span><span class="o">);</span>
  <span class="k">if</span> <span class="o">(</span><span class="n">newCount</span> <span class="o">==</span> <span class="mi">1L</span><span class="o">)</span> <span class="o">{</span>
    <span class="n">uniqueCountTable</span><span class="o">.</span><span class="na">increment</span><span class="o">(</span><span class="k">new</span> <span class="n">Increment</span><span class="o">(</span><span class="s">&quot;unique_count&quot;</span><span class="o">,</span> <span class="s">&quot;count&quot;</span><span class="o">,</span> <span class="mi">1L</span><span class="o">));</span>
  <span class="o">}</span>
<span class="o">}</span>
</pre></div>
</div>
<p>Finally, we write a method to retrieve the number of unique words seen:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="kd">public</span> <span class="n">Long</span> <span class="nf">readUniqueCount</span><span class="o">()</span> <span class="o">{</span>
  <span class="k">return</span> <span class="n">uniqueCountTable</span><span class="o">.</span><span class="na">get</span><span class="o">(</span><span class="k">new</span> <span class="n">Get</span><span class="o">(</span><span class="s">&quot;unique_count&quot;</span><span class="o">,</span> <span class="s">&quot;count&quot;</span><span class="o">)).</span><span class="na">getLong</span><span class="o">(</span><span class="s">&quot;count&quot;</span><span class="o">);</span>
<span class="o">}</span>
</pre></div>
</div>
<p>All administrative operations (such as create, drop, truncate) will be delegated to the embedded Datasets
in the order they are defined in the constructor. <tt class="docutils literal"><span class="pre">DatasetProperties</span></tt> that are passed during creation of
the Dataset will be passed as-is to the embedded Datasets.</p>
<p>To create a Dataset of type <tt class="docutils literal"><span class="pre">UniqueCountTable</span></tt>, add the following into the Application implementation:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="n">Class</span> <span class="n">MyApp</span> <span class="kd">extends</span> <span class="n">AbstractApplication</span> <span class="o">{</span>
  <span class="kd">public</span> <span class="kt">void</span> <span class="nf">configure</span><span class="o">()</span> <span class="o">{</span>
    <span class="n">createDataset</span><span class="o">(</span><span class="s">&quot;myCounters&quot;</span><span class="o">,</span> <span class="n">UniqueCountTable</span><span class="o">.</span><span class="na">class</span><span class="o">)</span>
    <span class="o">...</span>
  <span class="o">}</span>
<span class="o">}</span>
</pre></div>
</div>
<p>You can also pass <tt class="docutils literal"><span class="pre">DatasetProperties</span></tt> as a third parameter to the <tt class="docutils literal"><span class="pre">createDataset</span></tt> method.
These properties will be used by embedded Datasets during creation and will be available via the
<tt class="docutils literal"><span class="pre">DatasetSpecification</span></tt> passed to the Dataset constructor.</p>
<p>Application components can access a created Dataset via the <tt class="docutils literal"><span class="pre">&#64;UseDataSet</span></tt> annotation:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="n">Class</span> <span class="n">MyFlowlet</span> <span class="kd">extends</span> <span class="n">AbstractFlowlet</span> <span class="o">{</span>
  <span class="nd">@UseDataSet</span><span class="o">(</span><span class="s">&quot;myCounters&quot;</span><span class="o">)</span>
  <span class="kd">private</span> <span class="n">UniqueCountTable</span> <span class="n">counters</span><span class="o">;</span>
  <span class="o">...</span>
<span class="o">}</span>
</pre></div>
</div>
<p>A complete application demonstrating the use of a custom Dataset is included in our
<a class="reference internal" href="getstarted.html#purchase"><em>Purchase Example</em></a>.</p>
<p>You can also create, drop, and truncate Datasets using the
<a class="reference internal" href="api.html#rest-datasets"><em>Cask Data Application Platform HTTP REST API</em></a>.</p>
</div>
<div class="section" id="datasets-and-mapreduce">
<h3>Datasets and MapReduce<a class="headerlink" href="#datasets-and-mapreduce" title="Permalink to this headline">¶</a></h3>
<p>A MapReduce job can interact with a Dataset by using it as an input or an output.
The Dataset needs to implement specific interfaces to support this.</p>
<p>When you run a MapReduce job, you can configure it to read its input from a Dataset. The
source Dataset must implement the <tt class="docutils literal"><span class="pre">BatchReadable</span></tt> interface, which requires two methods:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="kd">public</span> <span class="kd">interface</span> <span class="nc">BatchReadable</span><span class="o">&lt;</span><span class="n">KEY</span><span class="o">,</span> <span class="n">VALUE</span><span class="o">&gt;</span> <span class="o">{</span>
  <span class="n">List</span><span class="o">&lt;</span><span class="n">Split</span><span class="o">&gt;</span> <span class="nf">getSplits</span><span class="o">();</span>
  <span class="n">SplitReader</span><span class="o">&lt;</span><span class="n">KEY</span><span class="o">,</span> <span class="n">VALUE</span><span class="o">&gt;</span> <span class="n">createSplitReader</span><span class="o">(</span><span class="n">Split</span> <span class="n">split</span><span class="o">);</span>
<span class="o">}</span>
</pre></div>
</div>
<p>These two methods complement each other: <tt class="docutils literal"><span class="pre">getSplits()</span></tt> must return all splits of the Dataset
that the MapReduce job will read; <tt class="docutils literal"><span class="pre">createSplitReader()</span></tt> is then called in every Mapper to
read one of the splits. Note that the <tt class="docutils literal"><span class="pre">KEY</span></tt> and <tt class="docutils literal"><span class="pre">VALUE</span></tt> type parameters of the split reader
must match the input key and value type parameters of the Mapper.</p>
<p>Because <tt class="docutils literal"><span class="pre">getSplits()</span></tt> has no arguments, it will typically create splits that cover the
entire Dataset. If you want to use a custom selection of the input data, define another
method in your Dataset with additional parameters and explicitly set the input in the
<tt class="docutils literal"><span class="pre">beforeSubmit()</span></tt> method.</p>
<p>For example, the system Dataset <tt class="docutils literal"><span class="pre">KeyValueTable</span></tt> implements <tt class="docutils literal"><span class="pre">BatchReadable&lt;byte[],</span> <span class="pre">byte[]&gt;</span></tt>
with an extra method that allows specification of the number of splits and a range of keys:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="kd">public</span> <span class="kd">class</span> <span class="nc">KeyValueTable</span> <span class="kd">extends</span> <span class="n">AbstractDataset</span>
                           <span class="kd">implements</span> <span class="n">BatchReadable</span><span class="o">&lt;</span><span class="kt">byte</span><span class="o">[],</span> <span class="kt">byte</span><span class="o">[]&gt;</span> <span class="o">{</span>
  <span class="o">...</span>
  <span class="kd">public</span> <span class="n">List</span><span class="o">&lt;</span><span class="n">Split</span><span class="o">&gt;</span> <span class="nf">getSplits</span><span class="o">(</span><span class="kt">int</span> <span class="n">numSplits</span><span class="o">,</span> <span class="kt">byte</span><span class="o">[]</span> <span class="n">start</span><span class="o">,</span> <span class="kt">byte</span><span class="o">[]</span> <span class="n">stop</span><span class="o">);</span>
<span class="o">}</span>
</pre></div>
</div>
<p>To read a range of keys and give a hint that you want 16 splits, write:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="nd">@Override</span>
<span class="nd">@UseDataSet</span><span class="o">(</span><span class="s">&quot;myTable&quot;</span><span class="o">)</span>
<span class="n">KeyValueTable</span> <span class="n">kvTable</span><span class="o">;</span>
<span class="o">...</span>
<span class="kd">public</span> <span class="kt">void</span> <span class="nf">beforeSubmit</span><span class="o">(</span><span class="n">MapReduceContext</span> <span class="n">context</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>
  <span class="o">...</span>
  <span class="n">context</span><span class="o">.</span><span class="na">setInput</span><span class="o">(</span><span class="n">kvTable</span><span class="o">,</span> <span class="n">kvTable</span><span class="o">.</span><span class="na">getSplits</span><span class="o">(</span><span class="mi">16</span><span class="o">,</span> <span class="n">startKey</span><span class="o">,</span> <span class="n">stopKey</span><span class="o">);</span>
<span class="o">}</span>
</pre></div>
</div>
<p>Just as you have the option to read input from a Dataset, you have the option to write to a Dataset as
the output destination of a MapReduce job if that Dataset implements the <tt class="docutils literal"><span class="pre">BatchWritable</span></tt>
interface:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="kd">public</span> <span class="kd">interface</span> <span class="nc">BatchWritable</span><span class="o">&lt;</span><span class="n">KEY</span><span class="o">,</span> <span class="n">VALUE</span><span class="o">&gt;</span> <span class="o">{</span>
  <span class="kt">void</span> <span class="nf">write</span><span class="o">(</span><span class="n">KEY</span> <span class="n">key</span><span class="o">,</span> <span class="n">VALUE</span> <span class="n">value</span><span class="o">);</span>
<span class="o">}</span>
</pre></div>
</div>
<p>The <tt class="docutils literal"><span class="pre">write()</span></tt> method is used to redirect all writes performed by a Reducer to the Dataset.
Again, the <tt class="docutils literal"><span class="pre">KEY</span></tt> and <tt class="docutils literal"><span class="pre">VALUE</span></tt> type parameters must match the output key and value type
parameters of the Reducer.</p>
</div>
</div>
<div class="section" id="data-exploration">
<span id="data-explore"></span><h2>Data Exploration<a class="headerlink" href="#data-exploration" title="Permalink to this headline">¶</a></h2>
<p>It is often useful to be able to explore a Dataset in an ad-hoc manner.
This can be done using SQL if your Dataset fulfills two requirements:</p>
<ul class="simple">
<li>it defines the schema for each record; and</li>
<li>it has a method to scan its data record by record.</li>
</ul>
<p>For CDAP Datasets, this is done by implementing the <tt class="docutils literal"><span class="pre">RecordScannable</span></tt> interface.
The CDAP built-in Dataset <tt class="docutils literal"><span class="pre">KeyValueTable</span></tt> already implements this and can be used for ad-hoc queries.</p>
<p>Let&#8217;s take a closer look at the <tt class="docutils literal"><span class="pre">RecordScannable</span></tt> interface.</p>
<div class="section" id="defining-the-record-schema">
<h3>Defining the Record Schema<a class="headerlink" href="#defining-the-record-schema" title="Permalink to this headline">¶</a></h3>
<p>The record schema is given by returning the Java type of each record, and CDAP will derive the record schema from
that type:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="n">Type</span> <span class="nf">getRecordType</span><span class="o">();</span>
</pre></div>
</div>
<p>For example, suppose you have a class <tt class="docutils literal"><span class="pre">Entry</span></tt> defined as:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="kd">class</span> <span class="nc">Entry</span> <span class="o">{</span>
  <span class="kd">private</span> <span class="kd">final</span> <span class="n">String</span> <span class="n">key</span><span class="o">;</span>
  <span class="kd">private</span> <span class="kd">final</span> <span class="kt">int</span> <span class="n">value</span><span class="o">;</span>
  <span class="o">...</span>
<span class="o">}</span>
</pre></div>
</div>
<p>You can implement a record-scannable Dataset that uses <tt class="docutils literal"><span class="pre">Entry</span></tt> as the record type:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="kd">class</span> <span class="nc">MyDataset</span> <span class="o">...</span> <span class="kd">implements</span> <span class="n">RecordScannable</span><span class="o">&lt;</span><span class="n">Entry</span><span class="o">&gt;</span> <span class="o">{</span>
  <span class="o">...</span>
  <span class="kd">public</span> <span class="n">Type</span> <span class="nf">getRecordType</span><span class="o">()</span> <span class="o">{</span>
    <span class="k">return</span> <span class="n">Entry</span><span class="o">.</span><span class="na">class</span><span class="o">;</span>
  <span class="o">}</span>
</pre></div>
</div>
<p>Note that Java&#8217;s <tt class="docutils literal"><span class="pre">Class</span></tt> implements <tt class="docutils literal"><span class="pre">Type</span></tt> and you can simply return <tt class="docutils literal"><span class="pre">Entry.class</span></tt> as the record type.
CDAP will use reflection to infer a SQL-style schema from the record type.</p>
<p>In the case of the above class <tt class="docutils literal"><span class="pre">Entry</span></tt>, the schema will be:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="o">(</span><span class="n">key</span> <span class="n">STRING</span><span class="o">,</span> <span class="n">value</span> <span class="n">INT</span><span class="o">)</span>
</pre></div>
</div>
</div>
<div class="section" id="limitations">
<span id="sql-limitations"></span><h3>Limitations<a class="headerlink" href="#limitations" title="Permalink to this headline">¶</a></h3>
<ul>
<li><p class="first">The record type must be a structured type, that is, a Java class with fields. This is because SQL tables require
a structure type at the top level. This means the record type cannot be a primitive,
collection or map type. However, these types may appear nested inside the record type.</p>
</li>
<li><p class="first">The record type must be that of an actual Java class, not an interface. The same applies to the types of any
fields contained in the type. The reason is that interfaces only define methods but not fields; hence, reflection
would not be able to derive any fields or types from the interface.</p>
<p>The one exception to this rule is that Java collections such as <tt class="docutils literal"><span class="pre">List</span></tt> and <tt class="docutils literal"><span class="pre">Set</span></tt> are supported as well as
Java <tt class="docutils literal"><span class="pre">Map</span></tt>. This is possible because these interfaces are so commonly used that they deserve special handling.
These interfaces are parameterized and require special care as described in the next section.</p>
</li>
<li><p class="first">The record type must not be recursive. In other words, it cannot contain any class that directly or indirectly
contains a member of that same class. This is because a recursive type cannot be represented as a SQL schema.</p>
</li>
<li><p class="first">Fields of a class that are declared static or transient are ignored during schema generation. This means that the
record type must have at least one non-transient and non-static field. For example,
the <tt class="docutils literal"><span class="pre">java.util.Date</span></tt> class has only static and transient fields. Therefore a record type of <tt class="docutils literal"><span class="pre">Date</span></tt> is not
supported and will result in an exception when the Dataset is created.</p>
</li>
<li><p class="first">A Dataset can only be used in ad-hoc queries if its record type is completely contained in the Dataset definition.
This means that if the record type is or contains a parameterized type, then the type parameters must be present in
the Dataset definition. The reason is that the record type must be instantiated when executing an ad-hoc query.
If a type parameter depends on the jar file of the application that created the Dataset, then this jar file is not
available to the query execution runtime.</p>
<p>For example, you cannot execute ad-hoc queries over an <tt class="docutils literal"><span class="pre">ObjectStore&lt;MyObject&gt;</span></tt> if the <tt class="docutils literal"><span class="pre">MyObject</span></tt> is contained in
the application jar. However, if you define your own Dataset type <tt class="docutils literal"><span class="pre">MyObjectStore</span></tt> that extends or encapsulates an
<tt class="docutils literal"><span class="pre">ObjectStore&lt;MyObject&gt;</span></tt>, then <tt class="docutils literal"><span class="pre">MyObject</span></tt> becomes part of the Dataset definition for <tt class="docutils literal"><span class="pre">MyObjectStore</span></tt>. See the
<a class="reference internal" href="getstarted.html#purchase"><em>Purchase</em></a> application for an example.</p>
</li>
</ul>
</div>
<div class="section" id="parameterized-types">
<h3>Parameterized Types<a class="headerlink" href="#parameterized-types" title="Permalink to this headline">¶</a></h3>
<p>Suppose instead of being fixed to <tt class="docutils literal"><span class="pre">String</span></tt> and <tt class="docutils literal"><span class="pre">int</span></tt>, the <tt class="docutils literal"><span class="pre">Entry</span></tt> class is generic with type parameters for both
key and value:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="kd">class</span> <span class="nc">GenericEntry</span><span class="o">&lt;</span><span class="n">KEY</span><span class="o">,</span> <span class="n">VALUE</span><span class="o">&gt;</span> <span class="o">{</span>
  <span class="kd">private</span> <span class="kd">final</span> <span class="n">KEY</span> <span class="n">key</span><span class="o">;</span>
  <span class="kd">private</span> <span class="kd">final</span> <span class="n">VALUE</span> <span class="n">value</span><span class="o">;</span>
  <span class="o">...</span>
<span class="o">}</span>
</pre></div>
</div>
<p>We should easily be able to implement <tt class="docutils literal"><span class="pre">RecordScannable&lt;GenericEntry&lt;String,</span> <span class="pre">Integer&gt;&gt;</span></tt> by defining <tt class="docutils literal"><span class="pre">getRecordType()</span></tt>.
However, due to Java&#8217;s runtime type erasure, returning <tt class="docutils literal"><span class="pre">GenericEntry.class</span></tt> does not convey complete information
about the record type. With reflection, CDAP can only determine the names of the two fields, but not their types.</p>
<p>To convey information about the type parameters, we must instead return a <tt class="docutils literal"><span class="pre">ParameterizedType</span></tt>, which Java&#8217;s
<tt class="docutils literal"><span class="pre">Class</span></tt> does not implement. An easy way is to use Guava&#8217;s <tt class="docutils literal"><span class="pre">TypeToken</span></tt>:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="kd">class</span> <span class="nc">MyDataset</span> <span class="o">...</span> <span class="kd">implements</span> <span class="n">RecordScannable</span><span class="o">&lt;</span><span class="n">GenericEntry</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Integer</span><span class="o">&gt;&gt;</span>
  <span class="kd">public</span> <span class="n">Type</span> <span class="nf">getRecordType</span><span class="o">()</span> <span class="o">{</span>
    <span class="k">return</span> <span class="k">new</span> <span class="n">TypeToken</span><span class="o">&lt;</span><span class="n">GenericEntry</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Integer</span><span class="o">&gt;&gt;()</span> <span class="o">{</span> <span class="o">}.</span><span class="na">getType</span><span class="o">();</span>
  <span class="o">}</span>
</pre></div>
</div>
<p>While this seems a little more complex at first sight, it is the de-facto standard way of dealing with Java type
erasure.</p>
</div>
<div class="section" id="complex-types">
<h3>Complex Types<a class="headerlink" href="#complex-types" title="Permalink to this headline">¶</a></h3>
<p>Your record type can also contain nested structures, lists, or maps, and they will be mapped to type names as defined in
the <a class="reference external" href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL">Hive language manual</a>. For example, if
your record type is defined as:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="kd">class</span> <span class="nc">Movie</span> <span class="o">{</span>
  <span class="n">String</span> <span class="n">title</span><span class="o">;</span>
  <span class="kt">int</span> <span class="n">year</span><span class="o">;</span>
  <span class="n">Map</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;</span> <span class="n">cast</span><span class="o">;</span>
  <span class="n">List</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;</span> <span class="n">reviews</span><span class="o">;</span>
<span class="o">}</span>
</pre></div>
</div>
<p>The SQL schema of the dataset would be:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="o">(</span><span class="n">title</span> <span class="n">STRING</span><span class="o">,</span> <span class="n">year</span> <span class="n">INT</span><span class="o">,</span> <span class="n">cast</span> <span class="n">MAP</span><span class="o">&lt;</span><span class="n">STRING</span><span class="o">,</span> <span class="n">STRING</span><span class="o">&gt;,</span> <span class="n">reviews</span> <span class="n">ARRAY</span><span class="o">&lt;</span><span class="n">STRING</span><span class="o">&gt;)</span>
</pre></div>
</div>
<p>Refer to the Hive language manual for more details on schema and data types.</p>
</div>
<div class="section" id="scanning-records">
<span id="sql-scanning-records"></span><h3>Scanning Records<a class="headerlink" href="#scanning-records" title="Permalink to this headline">¶</a></h3>
<p>The second requirement for enabling SQL queries over a Dataset is to provide a means of scanning the Dataset record
by record. Similar to how the <tt class="docutils literal"><span class="pre">BatchReadable</span></tt> interface makes Datasets readable by Map/Reduce jobs by iterating
over pairs of key and value, <tt class="docutils literal"><span class="pre">RecordScannable</span></tt> iterates over records. You need to implement a method to partition the
Dataset into splits, and an additional method to create a record scanner for each split:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="n">List</span><span class="o">&lt;</span><span class="n">Split</span><span class="o">&gt;</span> <span class="nf">getSplits</span><span class="o">();</span>
<span class="n">RecordScanner</span><span class="o">&lt;</span><span class="n">RECORD</span><span class="o">&gt;</span> <span class="nf">createSplitRecordScanner</span><span class="o">(</span><span class="n">Split</span> <span class="n">split</span><span class="o">);</span>
</pre></div>
</div>
<p>The <tt class="docutils literal"><span class="pre">RecordScanner</span></tt> is very similar to a <tt class="docutils literal"><span class="pre">SplitReader</span></tt>; except that instead of <tt class="docutils literal"><span class="pre">nextKeyValue()</span></tt>,
<tt class="docutils literal"><span class="pre">getCurrentKey()</span></tt>, and <tt class="docutils literal"><span class="pre">getCurrentValue()</span></tt>, it implements <tt class="docutils literal"><span class="pre">nextRecord()</span></tt> and <tt class="docutils literal"><span class="pre">getCurrentRecord()</span></tt>.</p>
<p>Typically, you do not implement these methods from scratch but rely on the <tt class="docutils literal"><span class="pre">BatchReadable</span></tt>
implementation of the underlying Tables and Datasets. For example, if your Dataset is backed by a <tt class="docutils literal"><span class="pre">Table</span></tt>:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="kd">class</span> <span class="nc">MyDataset</span> <span class="kd">implements</span> <span class="n">Dataset</span><span class="o">,</span> <span class="n">RecordScannable</span><span class="o">&lt;</span><span class="n">Entry</span><span class="o">&gt;</span> <span class="o">{</span>

  <span class="kd">private</span> <span class="n">Table</span> <span class="n">table</span><span class="o">;</span>
  <span class="kd">private</span> <span class="kd">static</span> <span class="kd">final</span> <span class="kt">byte</span><span class="o">[]</span> <span class="n">VALUE_COLUMN</span> <span class="o">=</span> <span class="o">{</span> <span class="sc">&#39;c&#39;</span> <span class="o">};</span>

  <span class="c1">// ..</span>
  <span class="c1">// All other Dataset methods</span>
  <span class="c1">// ...</span>

  <span class="nd">@Override</span>
  <span class="kd">public</span> <span class="n">Type</span> <span class="nf">getRecordType</span><span class="o">()</span> <span class="o">{</span>
    <span class="k">return</span> <span class="n">Entry</span><span class="o">.</span><span class="na">class</span><span class="o">;</span>
  <span class="o">}</span>

  <span class="nd">@Override</span>
  <span class="kd">public</span> <span class="n">List</span><span class="o">&lt;</span><span class="n">Split</span><span class="o">&gt;</span> <span class="nf">getSplits</span><span class="o">()</span> <span class="o">{</span>
    <span class="k">return</span> <span class="n">table</span><span class="o">.</span><span class="na">getSplits</span><span class="o">();</span>
  <span class="o">}</span>

  <span class="nd">@Override</span>
  <span class="kd">public</span> <span class="n">RecordScanner</span><span class="o">&lt;</span><span class="n">Entry</span><span class="o">&gt;</span> <span class="nf">createSplitRecordScanner</span><span class="o">(</span><span class="n">Split</span> <span class="n">split</span><span class="o">)</span> <span class="o">{</span>

    <span class="kd">final</span> <span class="n">SplitReader</span><span class="o">&lt;</span><span class="kt">byte</span><span class="o">[],</span> <span class="n">Row</span><span class="o">&gt;</span> <span class="n">reader</span> <span class="o">=</span> <span class="n">table</span><span class="o">.</span><span class="na">createSplitReader</span><span class="o">(</span><span class="n">split</span><span class="o">);</span>

    <span class="k">return</span> <span class="k">new</span> <span class="n">RecordScanner</span><span class="o">&lt;</span><span class="n">Entry</span><span class="o">&gt;()</span> <span class="o">{</span>
      <span class="nd">@Override</span>
      <span class="kd">public</span> <span class="kt">void</span> <span class="nf">initialize</span><span class="o">(</span><span class="n">Split</span> <span class="n">split</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">reader</span><span class="o">.</span><span class="na">initialize</span><span class="o">(</span><span class="n">split</span><span class="o">);</span>
      <span class="o">}</span>

      <span class="nd">@Override</span>
      <span class="kd">public</span> <span class="kt">boolean</span> <span class="nf">nextRecord</span><span class="o">()</span> <span class="o">{</span>
        <span class="k">return</span> <span class="n">reader</span><span class="o">.</span><span class="na">nextKeyValue</span><span class="o">();</span>
      <span class="o">}</span>

      <span class="nd">@Override</span>
      <span class="kd">public</span> <span class="n">Entry</span> <span class="nf">getCurrentRecord</span><span class="o">()</span>  <span class="o">{</span>
        <span class="k">return</span> <span class="k">new</span> <span class="nf">Entry</span><span class="o">(</span>
          <span class="n">Bytes</span><span class="o">.</span><span class="na">toString</span><span class="o">(</span><span class="n">reader</span><span class="o">.</span><span class="na">getCurrentKey</span><span class="o">()),</span>
          <span class="n">reader</span><span class="o">.</span><span class="na">getCurrentValue</span><span class="o">().</span><span class="na">getInt</span><span class="o">(</span><span class="n">VALUE_COLUMN</span><span class="o">));</span>
      <span class="o">}</span>

      <span class="nd">@Override</span>
      <span class="kd">public</span> <span class="kt">void</span> <span class="nf">close</span><span class="o">()</span> <span class="o">{</span>
        <span class="n">reader</span><span class="o">.</span><span class="na">close</span><span class="o">();</span>
      <span class="o">}</span>

    <span class="o">}</span>
  <span class="o">}</span>
<span class="o">}</span>
</pre></div>
</div>
<p>While this is straightforward, it is even easier if your Dataset already implements <tt class="docutils literal"><span class="pre">BatchReadable</span></tt>.
In that case, you can reuse its implementation of <tt class="docutils literal"><span class="pre">getSplits()</span></tt> and implement the split record scanner
with a helper method
(<tt class="docutils literal"><span class="pre">Scannables.splitRecordScanner</span></tt>) already defined by CDAP. It takes a split reader and a <tt class="docutils literal"><span class="pre">RecordMaker</span></tt>
that transforms a key and value, as produced by the <tt class="docutils literal"><span class="pre">BatchReadable</span></tt>&#8216;s split reader,
into a record:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="nd">@Override</span>
<span class="kd">public</span> <span class="n">RecordScanner</span><span class="o">&lt;</span><span class="n">Entry</span><span class="o">&gt;</span> <span class="nf">createSplitRecordScanner</span><span class="o">(</span><span class="n">Split</span> <span class="n">split</span><span class="o">)</span> <span class="o">{</span>
  <span class="k">return</span> <span class="n">Scannables</span><span class="o">.</span><span class="na">splitRecordScanner</span><span class="o">(</span>
    <span class="n">table</span><span class="o">.</span><span class="na">createSplitReader</span><span class="o">(</span><span class="n">split</span><span class="o">),</span>
    <span class="k">new</span> <span class="n">Scannables</span><span class="o">.</span><span class="na">RecordMaker</span><span class="o">&lt;</span><span class="kt">byte</span><span class="o">[],</span> <span class="n">Row</span><span class="o">,</span> <span class="n">Entry</span><span class="o">&gt;()</span> <span class="o">{</span>
      <span class="nd">@Override</span>
      <span class="kd">public</span> <span class="n">Entry</span> <span class="nf">makeRecord</span><span class="o">(</span><span class="kt">byte</span><span class="o">[]</span> <span class="n">key</span><span class="o">,</span> <span class="n">Row</span> <span class="n">row</span><span class="o">)</span> <span class="o">{</span>
        <span class="k">return</span> <span class="k">new</span> <span class="nf">Entry</span><span class="o">(</span><span class="n">Bytes</span><span class="o">.</span><span class="na">toString</span><span class="o">(</span><span class="n">key</span><span class="o">),</span> <span class="n">row</span><span class="o">.</span><span class="na">getInt</span><span class="o">(</span><span class="n">VALUE_COLUMN</span><span class="o">));</span>
      <span class="o">}</span>
    <span class="o">});</span>
<span class="o">}</span>
</pre></div>
</div>
<p>Note there is an even simpler helper (<tt class="docutils literal"><span class="pre">Scannables.valueRecordScanner</span></tt>) that derives a split
record scanner from a split reader. For each key and value returned by the split reader it ignores the key
and returns the value. For example,
if your dataset implements <tt class="docutils literal"><span class="pre">BatchReadable&lt;String,</span> <span class="pre">Employee&gt;</span></tt>, then you can implement <tt class="docutils literal"><span class="pre">RecordScannable&lt;Employee&gt;</span></tt> by
defining:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="nd">@Override</span>
<span class="kd">public</span> <span class="n">RecordScanner</span><span class="o">&lt;</span><span class="n">Employee</span><span class="o">&gt;</span> <span class="nf">createSplitRecordScanner</span><span class="o">(</span><span class="n">Split</span> <span class="n">split</span><span class="o">)</span> <span class="o">{</span>
  <span class="k">return</span> <span class="n">Scannables</span><span class="o">.</span><span class="na">valueRecordScanner</span><span class="o">(</span><span class="n">table</span><span class="o">.</span><span class="na">createSplitReader</span><span class="o">(</span><span class="n">split</span><span class="o">));</span>
<span class="o">}</span>
</pre></div>
</div>
<p>An example demonstrating an implementation of <tt class="docutils literal"><span class="pre">RecordScannable</span></tt> is included in the Cask Data Application Platform SDK in the
directory <tt class="docutils literal"><span class="pre">examples/Purchase</span></tt>, namely the <tt class="docutils literal"><span class="pre">PurchaseHistoryStore</span></tt>.</p>
</div>
<div class="section" id="writing-to-datasets-with-sql">
<h3>Writing to Datasets with SQL<a class="headerlink" href="#writing-to-datasets-with-sql" title="Permalink to this headline">¶</a></h3>
<p>Data can be inserted into Datasets using SQL. For example, you can write to a Dataset named
<tt class="docutils literal"><span class="pre">ProductCatalog</span></tt> with this SQL query:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="n">INSERT</span> <span class="n">INTO</span> <span class="n">TABLE</span> <span class="n">cdap_user_productcatalog</span> <span class="n">SELECT</span> <span class="o">...</span>
</pre></div>
</div>
<p>In order for a Dataset to enable record insertion from SQL query, it simply has to expose a way to write records
into itself.</p>
<p>For CDAP Datasets, this is done by implementing the <tt class="docutils literal"><span class="pre">RecordWritable</span></tt> interface.
The system Dataset KeyValueTable already implements this and can be used to insert records from SQL queries.</p>
<p>Let&#8217;s take a closer look at the <tt class="docutils literal"><span class="pre">RecordWritable</span></tt> interface.</p>
<div class="section" id="id4">
<h4>Defining the Record Schema<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h4>
<p>Just like in the <tt class="docutils literal"><span class="pre">RecordScannable</span></tt> interface, the record schema is given by returning the Java type of each record,
using the method:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="n">Type</span> <span class="nf">getRecordType</span><span class="o">();</span>
</pre></div>
</div>
<p><a class="reference internal" href="#sql-limitations"><em>The same rules</em></a> that apply to the type of the <tt class="docutils literal"><span class="pre">RecordScannable</span></tt> interface apply
to the type of the <tt class="docutils literal"><span class="pre">RecordWritable</span></tt> interface. In fact, if a Dataset implements both <tt class="docutils literal"><span class="pre">RecordScannable</span></tt> and
<tt class="docutils literal"><span class="pre">RecordWritable</span></tt> interfaces, they will have to use identical record types.</p>
</div>
<div class="section" id="writing-records">
<h4>Writing Records<a class="headerlink" href="#writing-records" title="Permalink to this headline">¶</a></h4>
<p>To enable inserting SQL query results, a Dataset needs to provide a means of writing a record into itself.
This is similar to how the <tt class="docutils literal"><span class="pre">BatchWritable</span></tt> interface makes Datasets writable from MapReduce jobs by providing
a way to write pairs of key and value. You need to implement the <tt class="docutils literal"><span class="pre">RecordWritable</span></tt> method:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="kt">void</span> <span class="nf">write</span><span class="o">(</span><span class="n">RECORD</span> <span class="n">record</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">IOException</span><span class="o">;</span>
</pre></div>
</div>
<p>Continuing the <em>MyDataset</em> <a class="reference internal" href="#sql-scanning-records"><em>example used above</em></a>, which showed an implementation of
<tt class="docutils literal"><span class="pre">RecordScannable</span></tt>, this example an implementation of a <tt class="docutils literal"><span class="pre">RecordWritable</span></tt> Dataset that is backed by a <tt class="docutils literal"><span class="pre">Table</span></tt>:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="kd">class</span> <span class="nc">MyDataset</span> <span class="kd">implements</span> <span class="n">Dataset</span><span class="o">,</span> <span class="o">...,</span> <span class="n">RecordWritable</span><span class="o">&lt;</span><span class="n">Entry</span><span class="o">&gt;</span> <span class="o">{</span>

  <span class="kd">private</span> <span class="n">Table</span> <span class="n">table</span><span class="o">;</span>
  <span class="kd">private</span> <span class="kd">static</span> <span class="kd">final</span> <span class="kt">byte</span><span class="o">[]</span> <span class="n">VALUE_COLUMN</span> <span class="o">=</span> <span class="o">{</span> <span class="sc">&#39;c&#39;</span> <span class="o">};</span>

  <span class="c1">// ..</span>
  <span class="c1">// All other Dataset methods</span>
  <span class="c1">// ...</span>

  <span class="nd">@Override</span>
  <span class="kd">public</span> <span class="n">Type</span> <span class="nf">getRecordType</span><span class="o">()</span> <span class="o">{</span>
    <span class="k">return</span> <span class="n">Entry</span><span class="o">.</span><span class="na">class</span><span class="o">;</span>
  <span class="o">}</span>

  <span class="nd">@Override</span>
  <span class="kd">public</span> <span class="kt">void</span> <span class="nf">write</span><span class="o">(</span><span class="n">Entry</span> <span class="n">record</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">IOException</span> <span class="o">{</span>
    <span class="k">return</span> <span class="n">table</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="n">Bytes</span><span class="o">.</span><span class="na">toBytes</span><span class="o">(</span><span class="n">record</span><span class="o">.</span><span class="na">getKey</span><span class="o">()),</span> <span class="n">VALUE_COLUMN</span><span class="o">,</span> <span class="n">Bytes</span><span class="o">.</span><span class="na">toBytes</span><span class="o">(</span><span class="n">record</span><span class="o">.</span><span class="na">getValue</span><span class="o">()));</span>
  <span class="o">}</span>
<span class="o">}</span>
</pre></div>
</div>
<p>Note that a Dataset can implement either <tt class="docutils literal"><span class="pre">RecordScannable</span></tt>, <tt class="docutils literal"><span class="pre">RecordWritable</span></tt>, or both.</p>
</div>
</div>
<div class="section" id="connecting-to-cdap-datasets-using-cdap-jdbc-driver">
<h3>Connecting to CDAP Datasets using CDAP JDBC driver<a class="headerlink" href="#connecting-to-cdap-datasets-using-cdap-jdbc-driver" title="Permalink to this headline">¶</a></h3>
<p>CDAP provides a JDBC driver to make integrations with external programs and third-party BI (business intelligence)
tools easier.</p>
<p>The JDBC driver is a JAR that is bundled with the CDAP SDK. You can find it in the <tt class="docutils literal"><span class="pre">lib</span></tt>
directory of your SDK installation at <tt class="docutils literal"><span class="pre">lib/co.cask.cdap.cdap-explore-jdbc-&lt;version&gt;.jar</span></tt>.</p>
<p>If you don&#8217;t have a CDAP SDK and only want to connect to an existing instance of CDAP, you can download the CDAP JDBC
driver using this <a class="reference external" href="https://repository.continuuity.com/content/repositories/releases-public/co/cask/cdap/cdap-explore-jdbc/">link</a>.
Go to the directory matching the version of your running CDAP instance, and download the file named <tt class="docutils literal"><span class="pre">cdap-explore-jdbc-&lt;version&gt;.jar</span></tt>.</p>
<div class="section" id="using-the-cdap-jdbc-driver-in-your-java-code">
<h4>Using the CDAP JDBC driver in your Java code<a class="headerlink" href="#using-the-cdap-jdbc-driver-in-your-java-code" title="Permalink to this headline">¶</a></h4>
<p>To use CDAP JDBC driver in your code, place <tt class="docutils literal"><span class="pre">cdap-jdbc-driver.jar</span></tt> in the classpath of your application.
If you are using Maven, you can simply add a dependency in your file <tt class="docutils literal"><span class="pre">pom.xml</span></tt>:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="o">&lt;</span><span class="n">dependencies</span><span class="o">&gt;</span>
  <span class="o">...</span>
  <span class="o">&lt;</span><span class="n">dependency</span><span class="o">&gt;</span>
    <span class="o">&lt;</span><span class="n">groupId</span><span class="o">&gt;</span><span class="n">co</span><span class="o">.</span><span class="na">cask</span><span class="o">.</span><span class="na">cdap</span><span class="o">&lt;/</span><span class="n">groupId</span><span class="o">&gt;</span>
    <span class="o">&lt;</span><span class="n">artifactId</span><span class="o">&gt;</span><span class="n">cdap</span><span class="o">-</span><span class="n">explore</span><span class="o">-</span><span class="n">jdbc</span><span class="o">&lt;/</span><span class="n">artifactId</span><span class="o">&gt;</span>
    <span class="o">&lt;</span><span class="n">version</span><span class="o">&gt;&lt;!--</span> <span class="n">Version</span> <span class="n">of</span> <span class="n">CDAP</span> <span class="n">you</span> <span class="n">want</span> <span class="n">the</span> <span class="n">JDBC</span> <span class="n">driver</span> <span class="n">to</span> <span class="n">query</span> <span class="o">--&gt;&lt;/</span><span class="n">version</span><span class="o">&gt;</span>
  <span class="o">&lt;/</span><span class="n">dependency</span><span class="o">&gt;</span>
  <span class="o">...</span>
<span class="o">&lt;/</span><span class="n">dependencies</span><span class="o">&gt;</span>
</pre></div>
</div>
<p>Here is a snippet of Java code that uses the CDAP JDBC driver to connect to a running instance of CDAP,
and executes a query over CDAP Datasets:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="c1">// First, register the driver once in your application</span>
<span class="n">Class</span><span class="o">.</span><span class="na">forName</span><span class="o">(</span><span class="s">&quot;co.cask.cdap.explore.jdbc.ExploreDriver&quot;</span><span class="o">);</span>

<span class="c1">// If your CDAP instance requires a authorization token for connection,</span>
<span class="c1">// you have to specify it here.</span>
<span class="c1">// Replace &lt;cdap-host&gt; and &lt;authorization_token&gt; as appropriate to your installation.</span>
<span class="n">String</span> <span class="n">connectionUrl</span> <span class="o">=</span> <span class="s">&quot;jdbc:cdap://&lt;cdap-host&gt;:10000&quot;</span> <span class="o">+</span>
  <span class="s">&quot;?auth.token=&lt;authorization_token&gt;&quot;</span><span class="o">;</span>

<span class="c1">// Connect to CDAP instance</span>
<span class="n">Connection</span> <span class="n">connection</span> <span class="o">=</span> <span class="n">DriverManager</span><span class="o">.</span><span class="na">getConnection</span><span class="o">(</span><span class="n">connectionUrl</span><span class="o">);</span>

<span class="c1">// Execute a query over CDAP Datasets and retrieve the results</span>
<span class="n">ResultSet</span> <span class="n">resultSet</span> <span class="o">=</span> <span class="n">connection</span><span class="o">.</span><span class="na">prepareStatement</span><span class="o">(</span><span class="s">&quot;select * from cdap_user_mydataset&quot;</span><span class="o">).</span><span class="na">executeQuery</span><span class="o">();</span>
<span class="o">...</span>
</pre></div>
</div>
<p>JDBC drivers are a standard in the Java ecosystem, with many <a class="reference external" href="http://docs.oracle.com/javase/tutorial/jdbc/">resources about them available</a>.</p>
</div>
<div class="section" id="accessing-cdap-datasets-through-business-intelligence-tools">
<h4>Accessing CDAP Datasets through Business Intelligence Tools<a class="headerlink" href="#accessing-cdap-datasets-through-business-intelligence-tools" title="Permalink to this headline">¶</a></h4>
<p>Most Business Intelligence tools can integrate with relational databases using JDBC drivers. They often include
drivers to connect to standard databases such as MySQL or PostgreSQL.
Most tools allow the addition of non-standard JDBC drivers.</p>
<p>We&#8217;ll look at two business intelligence tools — <em>SquirrelSQL</em> and <em>Pentaho Data Integration</em> —
and see how to connect them to a running CDAP instance and interact with CDAP Datasets.</p>
</div>
<div class="section" id="squirrelsql">
<h4>SquirrelSQL<a class="headerlink" href="#squirrelsql" title="Permalink to this headline">¶</a></h4>
<p><em>SquirrelSQL</em> is a simple JDBC client which executes SQL queries against many different relational databases.
Here&#8217;s how to add the CDAP JDBC driver inside <em>SquirrelSQL</em>.</p>
<ol class="arabic">
<li><p class="first">Open the <tt class="docutils literal"><span class="pre">Drivers</span></tt> pane, located on the far left corner of <em>SquirrelSQL</em>.</p>
</li>
<li><p class="first">Click the <tt class="docutils literal"><span class="pre">+</span></tt> icon of the <tt class="docutils literal"><span class="pre">Drivers</span></tt> pane.</p>
<a class="reference internal image-reference" href="_images/squirrel_drivers.png"><img alt="_images/squirrel_drivers.png" src="_images/squirrel_drivers.png" style="width: 4in;" /></a>
</li>
<li><p class="first">Add a new Driver by entering a <tt class="docutils literal"><span class="pre">Name</span></tt>, such as <tt class="docutils literal"><span class="pre">CDAP</span> <span class="pre">Driver</span></tt>. The <tt class="docutils literal"><span class="pre">Example</span> <span class="pre">URL</span></tt> is of the form
<tt class="docutils literal"><span class="pre">jdbc:cdap://&lt;host&gt;:10000?auth.token=&lt;token&gt;</span></tt>. The <tt class="docutils literal"><span class="pre">Website</span> <span class="pre">URL</span></tt> can be left blank. In the <tt class="docutils literal"><span class="pre">Class</span> <span class="pre">Name</span></tt>
field, enter <tt class="docutils literal"><span class="pre">co.cask.cdap.explore.jdbc.ExploreDriver</span></tt>.
Click on the <tt class="docutils literal"><span class="pre">Extra</span> <span class="pre">Class</span> <span class="pre">Path</span></tt> tab, then on <tt class="docutils literal"><span class="pre">Add</span></tt>, and put the path to <tt class="docutils literal"><span class="pre">co.cask.cdap.cdap-explore-jdbc-&lt;version&gt;.jar</span></tt>.</p>
<a class="reference internal image-reference" href="_images/squirrel_add_driver.png"><img alt="_images/squirrel_add_driver.png" src="_images/squirrel_add_driver.png" style="width: 6in;" /></a>
</li>
<li><p class="first">Click on <tt class="docutils literal"><span class="pre">OK</span></tt>. You should now see <tt class="docutils literal"><span class="pre">Cask</span> <span class="pre">CDAP</span> <span class="pre">Driver</span></tt> in the list of drivers from the <tt class="docutils literal"><span class="pre">Drivers</span></tt> pane of
<em>SquirrelSQL</em>.</p>
</li>
<li><p class="first">We can now create an alias to connect to a running instance of CDAP. Open the <tt class="docutils literal"><span class="pre">Aliases</span></tt> pane, and click on
the <tt class="docutils literal"><span class="pre">+</span></tt> icon to create a new alias.</p>
</li>
<li><p class="first">In this example, we are going to connect to a standalone CDAP from the SDK.
The name of our alias will be <tt class="docutils literal"><span class="pre">CDAP</span> <span class="pre">Standalone</span></tt>. Select the <tt class="docutils literal"><span class="pre">CDAP</span> <span class="pre">Driver</span></tt> in
the list of available drivers. Our URL will be <tt class="docutils literal"><span class="pre">jdbc:cdap://localhost:10000</span></tt>. Our standalone instance
does not require an authorization token, but if yours requires one, HTML-encode your token
and pass it as a parameter of the <tt class="docutils literal"><span class="pre">URL</span></tt>. <tt class="docutils literal"><span class="pre">User</span> <span class="pre">Name</span></tt> and <tt class="docutils literal"><span class="pre">Password</span></tt> are left blank.</p>
<a class="reference internal image-reference" href="_images/squirrel_add_alias.png"><img alt="_images/squirrel_add_alias.png" src="_images/squirrel_add_alias.png" style="width: 6in;" /></a>
</li>
<li><p class="first">Click on <tt class="docutils literal"><span class="pre">OK</span></tt>. <tt class="docutils literal"><span class="pre">CDAP</span> <span class="pre">Standalone</span></tt> is now added to the list of aliases.</p>
</li>
<li><p class="first">A popup asks you to connect to your newly-added alias. Click on <tt class="docutils literal"><span class="pre">Connect</span></tt>, and <em>SquirrelSQL</em> will retrieve
information about your running CDAP Datasets.</p>
</li>
<li><p class="first">To execute a SQL query on your CDAP Datasets, go to the <tt class="docutils literal"><span class="pre">SQL</span></tt> tab, enter a query in the center field, and click
on the &#8220;running man&#8221; icon on top of the tab. Your results will show in the bottom half of the <em>SquirrelSQL</em> main view.</p>
<a class="reference internal image-reference" href="_images/squirrel_sql_query.png"><img alt="_images/squirrel_sql_query.png" src="_images/squirrel_sql_query.png" style="width: 6in;" /></a>
</li>
</ol>
</div>
<div class="section" id="pentaho-data-integration">
<h4>Pentaho Data Integration<a class="headerlink" href="#pentaho-data-integration" title="Permalink to this headline">¶</a></h4>
<p><em>Pentaho Data Integration</em> is an advanced, open source business intelligence tool that can execute
transformations of data coming from various sources. Let&#8217;s see how to connect it to
CDAP Datasets using the CDAP JDBC driver.</p>
<ol class="arabic">
<li><p class="first">Before opening the <em>Pentaho Data Integration</em> application, copy the <tt class="docutils literal"><span class="pre">co.cask.cdap.cdap-explore-jdbc-&lt;version&gt;.jar</span></tt>
file to the <tt class="docutils literal"><span class="pre">lib</span></tt> directory of <em>Pentaho Data Integration</em>, located at the root of the application&#8217;s directory.</p>
</li>
<li><p class="first">Open <em>Pentaho Data Integration</em>.</p>
</li>
<li><p class="first">In the toolbar, select <tt class="docutils literal"><span class="pre">File</span> <span class="pre">-&gt;</span> <span class="pre">New</span> <span class="pre">-&gt;</span> <span class="pre">Database</span> <span class="pre">Connection...</span></tt>.</p>
</li>
<li><p class="first">In the <tt class="docutils literal"><span class="pre">General</span></tt> section, select a <tt class="docutils literal"><span class="pre">Connection</span> <span class="pre">Name</span></tt>, like <tt class="docutils literal"><span class="pre">CDAP</span> <span class="pre">Standalone</span></tt>. For the <tt class="docutils literal"><span class="pre">Connection</span> <span class="pre">Type</span></tt>, select
<tt class="docutils literal"><span class="pre">Generic</span> <span class="pre">database</span></tt>. Select <tt class="docutils literal"><span class="pre">Native</span> <span class="pre">(JDBC)</span></tt> for the <tt class="docutils literal"><span class="pre">Access</span></tt> field. In this example, where we connect to
a standalone instance of CDAP, our <tt class="docutils literal"><span class="pre">Custom</span> <span class="pre">Connection</span> <span class="pre">URL</span></tt> will then be <tt class="docutils literal"><span class="pre">jdbc:cdap://localhost:10000</span></tt>.
In the field <tt class="docutils literal"><span class="pre">Custom</span> <span class="pre">Driver</span> <span class="pre">Class</span> <span class="pre">Name</span></tt>, enter <tt class="docutils literal"><span class="pre">co.cask.cdap.explore.jdbc.ExploreDriver</span></tt>.</p>
<a class="reference internal image-reference" href="_images/pentaho_add_connection.png"><img alt="_images/pentaho_add_connection.png" src="_images/pentaho_add_connection.png" style="width: 6in;" /></a>
</li>
<li><p class="first">Click on <tt class="docutils literal"><span class="pre">OK</span></tt>.</p>
</li>
<li><p class="first">To use this connection, navigate to the <tt class="docutils literal"><span class="pre">Design</span></tt> tab on the left of the main view. In the <tt class="docutils literal"><span class="pre">Input</span></tt> menu,
double click on <tt class="docutils literal"><span class="pre">Table</span> <span class="pre">input</span></tt>. It will create a new transformation containing this input.</p>
<a class="reference internal image-reference" href="_images/pentaho_table_input.png"><img alt="_images/pentaho_table_input.png" src="_images/pentaho_table_input.png" style="width: 6in;" /></a>
</li>
<li><p class="first">Right-click on <tt class="docutils literal"><span class="pre">Table</span> <span class="pre">input</span></tt> in your transformation and select <tt class="docutils literal"><span class="pre">Edit</span> <span class="pre">step</span></tt>. You can specify an appropriate name
for this input such as <tt class="docutils literal"><span class="pre">CDAP</span> <span class="pre">Datasets</span> <span class="pre">query</span></tt>. Under <tt class="docutils literal"><span class="pre">Connection</span></tt>, select the newly created database connection;
in this example, <tt class="docutils literal"><span class="pre">CDAP</span> <span class="pre">Standalone</span></tt>. Enter a valid SQL query in the main <tt class="docutils literal"><span class="pre">SQL</span></tt> field. This will define the data
available to your transformation.</p>
<a class="reference internal image-reference" href="_images/pentaho_modify_input.png"><img alt="_images/pentaho_modify_input.png" src="_images/pentaho_modify_input.png" style="width: 6in;" /></a>
</li>
<li><p class="first">Click on <tt class="docutils literal"><span class="pre">OK</span></tt>. Your input is now ready to be used in your transformation, and it will contain data coming
from the results of the SQL query on the CDAP Datasets.</p>
</li>
<li><p class="first">For more information on how to add components to a transformation and link them together, see the
<a class="reference external" href="http://community.pentaho.com/projects/data-integration/">Pentaho Data Integration page</a>.</p>
</li>
</ol>
</div>
</div>
<div class="section" id="formulating-queries">
<h3>Formulating Queries<a class="headerlink" href="#formulating-queries" title="Permalink to this headline">¶</a></h3>
<p>When creating your queries, keep these limitations in mind:</p>
<ul class="simple">
<li>The query syntax of CDAP is a subset of the variant of SQL that was first defined by Apache Hive.</li>
<li>The SQL commands <tt class="docutils literal"><span class="pre">UPDATE</span></tt> and <tt class="docutils literal"><span class="pre">DELETE</span></tt> are not allowed on CDAP Datasets.</li>
<li>When addressing your datasets in queries, you need to prefix the data set name with the CDAP
namespace <tt class="docutils literal"><span class="pre">cdap_user_</span></tt>. For example, if your Dataset is named <tt class="docutils literal"><span class="pre">ProductCatalog</span></tt>, then the corresponding table
name is <tt class="docutils literal"><span class="pre">cdap_user_productcatalog</span></tt>. Note that the table name is lower-case.</li>
</ul>
<p>For more examples of queries, please refer to the <a class="reference external" href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DML#LanguageManualDML-InsertingdataintoHiveTablesfromqueries">Hive language manual</a>.</p>
</div>
</div>
<div class="section" id="application-virtualization">
<h2>Application Virtualization<a class="headerlink" href="#application-virtualization" title="Permalink to this headline">¶</a></h2>
<p>Applications are a virtualization on top of your data, hiding low-level details of individual
programming paradigms and runtimes, while providing access to many useful and powerful services provided
by CDAP such as the ability to dynamically scale processing units, distributed transactions, and service
discovery. Applications are abstracted away from the platform that runs the application.
When you deploy and run the application into a specific installation of CDAP, the appropriate
implementations of all services and program runtimes are injected by CDAP; the application does not need
to change based on the environment. This allows you develop applications in one environment - like on your laptop
using a stand-alone CDAP for testing - and then seamlessly deploy it in a different environment - like
your distributed staging cluster.</p>
<p>With your data virtualized in CDAP as Streams and Datasets, you are able to process that data in realtime or in batch
using Programs (Flows, MapReduce, Spark, Workflow), and you can serve data to external clients using Services
and Procedures.</p>
</div>
<div class="section" id="applications">
<span id="id5"></span><h2>Applications<a class="headerlink" href="#applications" title="Permalink to this headline">¶</a></h2>
<p>An <strong>Application</strong> is a collection of Programs, Services, and Procedures that read from and write to the data
virtualization layer in CDAP. Programs include <a class="reference internal" href="#flows">Flows</a>, <a class="reference internal" href="#mapreduce">MapReduce</a>, <a class="reference internal" href="#workflows">Workflows</a>, and <a class="reference internal" href="#spark">Spark</a>, and are used
to process data. Services and Procedures are used to serve data.</p>
<p>The CDAP API is written in a
<a class="reference external" href="http://en.wikipedia.org/wiki/Fluent_interface">&#8220;fluent&#8221; interface style</a>,
and often relies on <tt class="docutils literal"><span class="pre">Builder</span></tt> methods for creating many parts of the Application.</p>
<p>In writing a CDAP Application, it&#8217;s best to use an integrated
development environment that understands the application interface to
provide code-completion in writing interface methods.</p>
<p>To create an Application, implement the <tt class="docutils literal"><span class="pre">Application</span></tt> interface
or subclass from <tt class="docutils literal"><span class="pre">AbstractApplication</span></tt> class, specifying
the Application metadata and declaring and configuring each of the Application elements:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="kd">public</span> <span class="kd">class</span> <span class="nc">MyApp</span> <span class="kd">extends</span> <span class="n">AbstractApplication</span> <span class="o">{</span>
  <span class="nd">@Override</span>
  <span class="kd">public</span> <span class="kt">void</span> <span class="nf">configure</span><span class="o">()</span> <span class="o">{</span>
    <span class="n">setName</span><span class="o">(</span><span class="s">&quot;myApp&quot;</span><span class="o">);</span>
    <span class="n">setDescription</span><span class="o">(</span><span class="s">&quot;My Sample Application&quot;</span><span class="o">);</span>
    <span class="n">addStream</span><span class="o">(</span><span class="k">new</span> <span class="n">Stream</span><span class="o">(</span><span class="s">&quot;myAppStream&quot;</span><span class="o">));</span>
    <span class="n">addFlow</span><span class="o">(</span><span class="k">new</span> <span class="n">MyAppFlow</span><span class="o">());</span>
    <span class="n">addProcedure</span><span class="o">(</span><span class="k">new</span> <span class="n">MyAppQuery</span><span class="o">());</span>
    <span class="n">addMapReduce</span><span class="o">(</span><span class="k">new</span> <span class="n">MyMapReduceJob</span><span class="o">());</span>
    <span class="n">addWorkflow</span><span class="o">(</span><span class="k">new</span> <span class="n">MyAppWorkflow</span><span class="o">());</span>
  <span class="o">}</span>
<span class="o">}</span>
</pre></div>
</div>
<p>Notice that <em>Streams</em> are
defined using provided <tt class="docutils literal"><span class="pre">Stream</span></tt> class, and are referenced by names, while
other components are defined using user-written
classes that implement correspondent interfaces and are referenced by passing
an object, in addition to being assigned a unique name.</p>
<p>Names used for <em>Streams</em> and <em>Datasets</em> need to be unique across the
CDAP instance, while names used for Programs and Services need to be unique only to the application.</p>
</div>
<div class="section" id="flows">
<span id="id6"></span><h2>Flows<a class="headerlink" href="#flows" title="Permalink to this headline">¶</a></h2>
<p><strong>Flows</strong> are user-implemented real-time stream processors. They are comprised of one or
more <strong>Flowlets</strong> that are wired together into a directed acyclic graph or DAG. Flowlets
pass data between one another; each Flowlet is able to perform custom logic and execute
data operations for each individual data object it processes. All data operations happen
in a consistent and durable way.</p>
<p>When processing a single input object, all operations, including the
removal of the object from the input, and emission of data to the
outputs, are executed in a transaction. This provides us with Atomicity,
Consistency, Isolation, and Durability (ACID) properties, and helps
assure a unique and core property of the Flow system: it guarantees
atomic and &#8220;exactly-once&#8221; processing of each input object by each
Flowlet in the DAG.</p>
<p>Flows are deployed to the CDAP instance and hosted within containers. Each
Flowlet instance runs in its own container. Each Flowlet in the DAG can
have multiple concurrent instances, each consuming a partition of the
Flowlet’s inputs.</p>
<p>To put data into your Flow, you can either connect the input of the Flow
to a Stream, or you can implement a Flowlet to generate or pull the data
from an external source.</p>
<p>The <tt class="docutils literal"><span class="pre">Flow</span></tt> interface allows you to specify the Flow’s metadata, <a class="reference internal" href="#flowlets">Flowlets</a>,
<a class="reference external" href="#connecting-flowlets">Flowlet connections</a>, <a class="reference external" href="#connection">Stream to Flowlet connections</a>,
and any <a class="reference internal" href="#datasets">Datasets</a> used in the Flow.</p>
<p>To create a Flow, implement <tt class="docutils literal"><span class="pre">Flow</span></tt> via a <tt class="docutils literal"><span class="pre">configure</span></tt> method that
returns a <tt class="docutils literal"><span class="pre">FlowSpecification</span></tt> using <tt class="docutils literal"><span class="pre">FlowSpecification.Builder()</span></tt>:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="kd">class</span> <span class="nc">MyExampleFlow</span> <span class="kd">implements</span> <span class="n">Flow</span> <span class="o">{</span>
  <span class="nd">@Override</span>
  <span class="kd">public</span> <span class="n">FlowSpecification</span> <span class="nf">configure</span><span class="o">()</span> <span class="o">{</span>
    <span class="k">return</span> <span class="n">FlowSpecification</span><span class="o">.</span><span class="na">Builder</span><span class="o">.</span><span class="na">with</span><span class="o">()</span>
      <span class="o">.</span><span class="na">setName</span><span class="o">(</span><span class="s">&quot;mySampleFlow&quot;</span><span class="o">)</span>
      <span class="o">.</span><span class="na">setDescription</span><span class="o">(</span><span class="s">&quot;Flow for showing examples&quot;</span><span class="o">)</span>
      <span class="o">.</span><span class="na">withFlowlets</span><span class="o">()</span>
        <span class="o">.</span><span class="na">add</span><span class="o">(</span><span class="s">&quot;flowlet1&quot;</span><span class="o">,</span> <span class="k">new</span> <span class="n">MyExampleFlowlet</span><span class="o">())</span>
        <span class="o">.</span><span class="na">add</span><span class="o">(</span><span class="s">&quot;flowlet2&quot;</span><span class="o">,</span> <span class="k">new</span> <span class="n">MyExampleFlowlet2</span><span class="o">())</span>
      <span class="o">.</span><span class="na">connect</span><span class="o">()</span>
        <span class="o">.</span><span class="na">fromStream</span><span class="o">(</span><span class="s">&quot;myStream&quot;</span><span class="o">).</span><span class="na">to</span><span class="o">(</span><span class="s">&quot;flowlet1&quot;</span><span class="o">)</span>
        <span class="o">.</span><span class="na">from</span><span class="o">(</span><span class="s">&quot;flowlet1&quot;</span><span class="o">).</span><span class="na">to</span><span class="o">(</span><span class="s">&quot;flowlet2&quot;</span><span class="o">)</span>
      <span class="o">.</span><span class="na">build</span><span class="o">();</span>
<span class="o">}</span>
</pre></div>
</div>
<p>In this example, the <em>name</em>, <em>description</em>, <em>with</em> (or <em>without</em>)
Flowlets, and <em>connections</em> are specified before building the Flow.</p>
<div class="section" id="flowlets">
<span id="id7"></span><h3>Flowlets<a class="headerlink" href="#flowlets" title="Permalink to this headline">¶</a></h3>
<p><strong>Flowlets</strong>, the basic building blocks of a Flow, represent each
individual processing node within a Flow. Flowlets consume data objects
from their inputs and execute custom logic on each data object, allowing
you to perform data operations as well as emit data objects to the
Flowlet’s outputs. Flowlets specify an <tt class="docutils literal"><span class="pre">initialize()</span></tt> method, which is
executed at the startup of each instance of a Flowlet before it receives
any data.</p>
<p>The example below shows a Flowlet that reads <em>Double</em> values, rounds
them, and emits the results. It has a simple configuration method and
doesn&#8217;t do anything for initialization or destruction:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="kd">class</span> <span class="nc">RoundingFlowlet</span> <span class="kd">implements</span> <span class="n">Flowlet</span> <span class="o">{</span>

  <span class="nd">@Override</span>
  <span class="kd">public</span> <span class="n">FlowletSpecification</span> <span class="nf">configure</span><span class="o">()</span> <span class="o">{</span>
    <span class="k">return</span> <span class="n">FlowletSpecification</span><span class="o">.</span><span class="na">Builder</span><span class="o">.</span><span class="na">with</span><span class="o">().</span>
      <span class="n">setName</span><span class="o">(</span><span class="s">&quot;round&quot;</span><span class="o">).</span>
      <span class="n">setDescription</span><span class="o">(</span><span class="s">&quot;A rounding Flowlet&quot;</span><span class="o">).</span>
      <span class="n">build</span><span class="o">();</span>
  <span class="o">}</span>

  <span class="nd">@Override</span>
  <span class="kd">public</span> <span class="kt">void</span> <span class="nf">initialize</span><span class="o">(</span><span class="n">FlowletContext</span> <span class="n">context</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>
  <span class="o">}</span>

  <span class="nd">@Override</span>
  <span class="kd">public</span> <span class="kt">void</span> <span class="nf">destroy</span><span class="o">()</span> <span class="o">{</span>
  <span class="o">}</span>

  <span class="n">OutputEmitter</span><span class="o">&lt;</span><span class="n">Long</span><span class="o">&gt;</span> <span class="n">output</span><span class="o">;</span>
  <span class="nd">@ProcessInput</span>
  <span class="kd">public</span> <span class="kt">void</span> <span class="nf">round</span><span class="o">(</span><span class="n">Double</span> <span class="n">number</span><span class="o">)</span> <span class="o">{</span>
    <span class="n">output</span><span class="o">.</span><span class="na">emit</span><span class="o">(</span><span class="n">Math</span><span class="o">.</span><span class="na">round</span><span class="o">(</span><span class="n">number</span><span class="o">));</span>
  <span class="o">}</span>
</pre></div>
</div>
<p>The most interesting method of this Flowlet is <tt class="docutils literal"><span class="pre">round()</span></tt>, the method
that does the actual processing. It uses an output emitter to send data
to its output. This is the only way that a Flowlet can emit output to
another connected Flowlet:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="n">OutputEmitter</span><span class="o">&lt;</span><span class="n">Long</span><span class="o">&gt;</span> <span class="n">output</span><span class="o">;</span>
<span class="nd">@ProcessInput</span>
<span class="kd">public</span> <span class="kt">void</span> <span class="nf">round</span><span class="o">(</span><span class="n">Double</span> <span class="n">number</span><span class="o">)</span> <span class="o">{</span>
  <span class="n">output</span><span class="o">.</span><span class="na">emit</span><span class="o">(</span><span class="n">Math</span><span class="o">.</span><span class="na">round</span><span class="o">(</span><span class="n">number</span><span class="o">));</span>
<span class="o">}</span>
</pre></div>
</div>
<p>Note that the Flowlet declares the output emitter but does not
initialize it. The Flow system initializes and injects its
implementation at runtime.</p>
<p>The method is annotated with <tt class="docutils literal"><span class="pre">&#64;ProcessInput</span></tt> — this tells the Flow
system that this method can process input data.</p>
<p>You can overload the process method of a Flowlet by adding multiple
methods with different input types. When an input object comes in, the
Flowlet will call the method that matches the object’s type:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="n">OutputEmitter</span><span class="o">&lt;</span><span class="n">Long</span><span class="o">&gt;</span> <span class="n">output</span><span class="o">;</span>

<span class="nd">@ProcessInput</span>
<span class="kd">public</span> <span class="kt">void</span> <span class="nf">round</span><span class="o">(</span><span class="n">Double</span> <span class="n">number</span><span class="o">)</span> <span class="o">{</span>
  <span class="n">output</span><span class="o">.</span><span class="na">emit</span><span class="o">(</span><span class="n">Math</span><span class="o">.</span><span class="na">round</span><span class="o">(</span><span class="n">number</span><span class="o">));</span>
<span class="o">}</span>
<span class="nd">@ProcessInput</span>
<span class="kd">public</span> <span class="kt">void</span> <span class="nf">round</span><span class="o">(</span><span class="n">Float</span> <span class="n">number</span><span class="o">)</span> <span class="o">{</span>
  <span class="n">output</span><span class="o">.</span><span class="na">emit</span><span class="o">((</span><span class="kt">long</span><span class="o">)</span><span class="n">Math</span><span class="o">.</span><span class="na">round</span><span class="o">(</span><span class="n">number</span><span class="o">));</span>
<span class="o">}</span>
</pre></div>
</div>
<p>If you define multiple process methods, a method will be selected based
on the input object’s origin; that is, the name of a Stream or the name
of an output of a Flowlet.</p>
<p>A Flowlet that emits data can specify this name using an annotation on
the output emitter. In the absence of this annotation, the name of the
output defaults to “out”:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="nd">@Output</span><span class="o">(</span><span class="s">&quot;code&quot;</span><span class="o">)</span>
<span class="n">OutputEmitter</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;</span> <span class="n">out</span><span class="o">;</span>
</pre></div>
</div>
<p>Data objects emitted through this output can then be directed to a
process method of a receiving Flowlet by annotating the method with the
origin name:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="nd">@ProcessInput</span><span class="o">(</span><span class="s">&quot;code&quot;</span><span class="o">)</span>
<span class="kd">public</span> <span class="kt">void</span> <span class="nf">tokenizeCode</span><span class="o">(</span><span class="n">String</span> <span class="n">text</span><span class="o">)</span> <span class="o">{</span>
  <span class="o">...</span> <span class="c1">// perform fancy code tokenization</span>
<span class="o">}</span>
</pre></div>
</div>
<div class="section" id="input-context">
<h4>Input Context<a class="headerlink" href="#input-context" title="Permalink to this headline">¶</a></h4>
<p>A process method can have an additional parameter, the <tt class="docutils literal"><span class="pre">InputContext</span></tt>.
The input context provides information about the input object, such as
its origin and the number of times the object has been retried. For
example, this Flowlet tokenizes text in a smart way and uses the input
context to decide which tokenizer to use:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="nd">@ProcessInput</span>
<span class="kd">public</span> <span class="kt">void</span> <span class="nf">tokenize</span><span class="o">(</span><span class="n">String</span> <span class="n">text</span><span class="o">,</span> <span class="n">InputContext</span> <span class="n">context</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>
  <span class="n">Tokenizer</span> <span class="n">tokenizer</span><span class="o">;</span>
  <span class="c1">// If this failed before, fall back to simple white space</span>
  <span class="k">if</span> <span class="o">(</span><span class="n">context</span><span class="o">.</span><span class="na">getRetryCount</span><span class="o">()</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="o">)</span> <span class="o">{</span>
    <span class="n">tokenizer</span> <span class="o">=</span> <span class="k">new</span> <span class="n">WhiteSpaceTokenizer</span><span class="o">();</span>
  <span class="o">}</span>
  <span class="c1">// Is this code? If its origin is named &quot;code&quot;, then assume yes</span>
  <span class="k">else</span> <span class="nf">if</span> <span class="o">(</span><span class="s">&quot;code&quot;</span><span class="o">.</span><span class="na">equals</span><span class="o">(</span><span class="n">context</span><span class="o">.</span><span class="na">getOrigin</span><span class="o">()))</span> <span class="o">{</span>
    <span class="n">tokenizer</span> <span class="o">=</span> <span class="k">new</span> <span class="n">CodeTokenizer</span><span class="o">();</span>
  <span class="o">}</span>
  <span class="k">else</span> <span class="o">{</span>
    <span class="c1">// Use the smarter tokenizer</span>
    <span class="n">tokenizer</span> <span class="o">=</span> <span class="k">new</span> <span class="n">NaturalLanguageTokenizer</span><span class="o">();</span>
  <span class="o">}</span>
  <span class="k">for</span> <span class="o">(</span><span class="n">String</span> <span class="n">token</span> <span class="o">:</span> <span class="n">tokenizer</span><span class="o">.</span><span class="na">tokenize</span><span class="o">(</span><span class="n">text</span><span class="o">))</span> <span class="o">{</span>
    <span class="n">output</span><span class="o">.</span><span class="na">emit</span><span class="o">(</span><span class="n">token</span><span class="o">);</span>
  <span class="o">}</span>
<span class="o">}</span>
</pre></div>
</div>
</div>
<div class="section" id="type-projection">
<h4>Type Projection<a class="headerlink" href="#type-projection" title="Permalink to this headline">¶</a></h4>
<p>Flowlets perform an implicit projection on the input objects if they do
not match exactly what the process method accepts as arguments. This
allows you to write a single process method that can accept multiple
<strong>compatible</strong> types. For example, if you have a process method:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="nd">@ProcessInput</span>
<span class="n">count</span><span class="o">(</span><span class="n">String</span> <span class="n">word</span><span class="o">)</span> <span class="o">{</span>
  <span class="o">...</span>
<span class="o">}</span>
</pre></div>
</div>
<p>and you send data of type <tt class="docutils literal"><span class="pre">Long</span></tt> to this Flowlet, then that type does
not exactly match what the process method expects. You could now write
another process method for <tt class="docutils literal"><span class="pre">Long</span></tt> numbers:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="nd">@ProcessInput</span> <span class="n">count</span><span class="o">(</span><span class="n">Long</span> <span class="n">number</span><span class="o">)</span> <span class="o">{</span>
  <span class="n">count</span><span class="o">(</span><span class="n">number</span><span class="o">.</span><span class="na">toString</span><span class="o">());</span>
<span class="o">}</span>
</pre></div>
</div>
<p>and you could do that for every type that you might possibly want to
count, but that would be rather tedious. Type projection does this for
you automatically. If no process method is found that matches the type
of an object exactly, it picks a method that is compatible with the
object.</p>
<p>In this case, because Long can be converted into a String, it is
compatible with the original process method. Other compatible
conversions are:</p>
<ul>
<li><p class="first">Every primitive type that can be converted to a <tt class="docutils literal"><span class="pre">String</span></tt> is compatible with
<tt class="docutils literal"><span class="pre">String</span></tt>.</p>
</li>
<li><p class="first">Any numeric type is compatible with numeric types that can represent it.
For example, <tt class="docutils literal"><span class="pre">int</span></tt> is compatible with <tt class="docutils literal"><span class="pre">long</span></tt>, <tt class="docutils literal"><span class="pre">float</span></tt> and <tt class="docutils literal"><span class="pre">double</span></tt>,
and <tt class="docutils literal"><span class="pre">long</span></tt> is compatible with <tt class="docutils literal"><span class="pre">float</span></tt> and <tt class="docutils literal"><span class="pre">double</span></tt>, but <tt class="docutils literal"><span class="pre">long</span></tt> is not
compatible with <tt class="docutils literal"><span class="pre">int</span></tt> because <tt class="docutils literal"><span class="pre">int</span></tt> cannot represent every <tt class="docutils literal"><span class="pre">long</span></tt> value.</p>
</li>
<li><p class="first">A byte array is compatible with a <tt class="docutils literal"><span class="pre">ByteBuffer</span></tt> and vice versa.</p>
</li>
<li><p class="first">A collection of type A is compatible with a collection of type B,
if type A is compatible with type B.
Here, a collection can be an array or any Java <tt class="docutils literal"><span class="pre">Collection</span></tt>.
Hence, a <tt class="docutils literal"><span class="pre">List&lt;Integer&gt;</span></tt> is compatible with a <tt class="docutils literal"><span class="pre">String[]</span></tt> array.</p>
</li>
<li><p class="first">Two maps are compatible if their underlying types are compatible.
For example, a <tt class="docutils literal"><span class="pre">TreeMap&lt;Integer,</span> <span class="pre">Boolean&gt;</span></tt> is compatible with a
<tt class="docutils literal"><span class="pre">HashMap&lt;String,</span> <span class="pre">String&gt;</span></tt>.</p>
</li>
<li><p class="first">Other Java objects can be compatible if their fields are compatible.
For example, in the following class <tt class="docutils literal"><span class="pre">Point</span></tt> is compatible with <tt class="docutils literal"><span class="pre">Coordinate</span></tt>,
because all common fields between the two classes are compatible.
When projecting from <tt class="docutils literal"><span class="pre">Point</span></tt> to <tt class="docutils literal"><span class="pre">Coordinate</span></tt>, the color field is dropped,
whereas the projection from <tt class="docutils literal"><span class="pre">Coordinate</span></tt> to <tt class="docutils literal"><span class="pre">Point</span></tt> will leave the <tt class="docutils literal"><span class="pre">color</span></tt> field
as <tt class="docutils literal"><span class="pre">null</span></tt>:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="kd">class</span> <span class="nc">Point</span> <span class="o">{</span>
  <span class="kd">private</span> <span class="kt">int</span> <span class="n">x</span><span class="o">;</span>
  <span class="kd">private</span> <span class="kt">int</span> <span class="n">y</span><span class="o">;</span>
  <span class="kd">private</span> <span class="n">String</span> <span class="n">color</span><span class="o">;</span>
<span class="o">}</span>

<span class="kd">class</span> <span class="nc">Coordinates</span> <span class="o">{</span>
  <span class="kt">int</span> <span class="n">x</span><span class="o">;</span>
  <span class="kt">int</span> <span class="n">y</span><span class="o">;</span>
<span class="o">}</span>
</pre></div>
</div>
</li>
</ul>
<p>Type projections help you keep your code generic and reusable. They also
interact well with inheritance. If a Flowlet can process a specific
object class, then it can also process any subclass of that class.</p>
</div>
<div class="section" id="stream-event">
<h4>Stream Event<a class="headerlink" href="#stream-event" title="Permalink to this headline">¶</a></h4>
<p>A Stream event is a special type of object that comes in via Streams. It
consists of a set of headers represented by a map from String to String,
and a byte array as the body of the event. To consume a Stream with a
Flow, define a Flowlet that processes data of type <tt class="docutils literal"><span class="pre">StreamEvent</span></tt>:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="kd">class</span> <span class="nc">StreamReader</span> <span class="kd">extends</span> <span class="n">AbstractFlowlet</span> <span class="o">{</span>
  <span class="o">...</span>
  <span class="nd">@ProcessInput</span>
  <span class="kd">public</span> <span class="kt">void</span> <span class="nf">processEvent</span><span class="o">(</span><span class="n">StreamEvent</span> <span class="n">event</span><span class="o">)</span> <span class="o">{</span>
    <span class="o">...</span>
  <span class="o">}</span>
</pre></div>
</div>
</div>
<div class="section" id="tick-methods">
<h4>Tick Methods<a class="headerlink" href="#tick-methods" title="Permalink to this headline">¶</a></h4>
<p>A Flowlet’s method can be annotated with <tt class="docutils literal"><span class="pre">&#64;Tick</span></tt>. Instead of
processing data objects from a Flowlet input, this method is invoked
periodically, without arguments. This can be used, for example, to
generate data, or pull data from an external data source periodically on
a fixed cadence.</p>
<p>In this code snippet from the <em>CountRandom</em> example, the <tt class="docutils literal"><span class="pre">&#64;Tick</span></tt>
method in the Flowlet emits random numbers:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="kd">public</span> <span class="kd">class</span> <span class="nc">RandomSource</span> <span class="kd">extends</span> <span class="n">AbstractFlowlet</span> <span class="o">{</span>

  <span class="kd">private</span> <span class="n">OutputEmitter</span><span class="o">&lt;</span><span class="n">Integer</span><span class="o">&gt;</span> <span class="n">randomOutput</span><span class="o">;</span>

  <span class="kd">private</span> <span class="kd">final</span> <span class="n">Random</span> <span class="n">random</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Random</span><span class="o">();</span>

  <span class="nd">@Tick</span><span class="o">(</span><span class="n">delay</span> <span class="o">=</span> <span class="mi">1L</span><span class="o">,</span> <span class="n">unit</span> <span class="o">=</span> <span class="n">TimeUnit</span><span class="o">.</span><span class="na">MILLISECONDS</span><span class="o">)</span>
  <span class="kd">public</span> <span class="kt">void</span> <span class="nf">generate</span><span class="o">()</span> <span class="kd">throws</span> <span class="n">InterruptedException</span> <span class="o">{</span>
    <span class="n">randomOutput</span><span class="o">.</span><span class="na">emit</span><span class="o">(</span><span class="n">random</span><span class="o">.</span><span class="na">nextInt</span><span class="o">(</span><span class="mi">10000</span><span class="o">));</span>
  <span class="o">}</span>
<span class="o">}</span>
</pre></div>
</div>
<p>Note: &#64;Tick method calls are serial; subsequent calls to the tick
method will be made only after the previous &#64;Tick method call has returned.</p>
</div>
<div class="section" id="connecting-flowlets">
<h4>Connecting Flowlets<a class="headerlink" href="#connecting-flowlets" title="Permalink to this headline">¶</a></h4>
<p>There are multiple ways to connect the Flowlets of a Flow. The most
common form is to use the Flowlet name. Because the name of each Flowlet
defaults to its class name, when building the Flow specification you can
simply write:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="o">.</span><span class="na">withFlowlets</span><span class="o">()</span>
  <span class="o">.</span><span class="na">add</span><span class="o">(</span><span class="k">new</span> <span class="n">RandomGenerator</span><span class="o">())</span>
  <span class="o">.</span><span class="na">add</span><span class="o">(</span><span class="k">new</span> <span class="n">RoundingFlowlet</span><span class="o">())</span>
<span class="o">.</span><span class="na">connect</span><span class="o">()</span>
  <span class="o">.</span><span class="na">fromStream</span><span class="o">(</span><span class="s">&quot;RandomGenerator&quot;</span><span class="o">).</span><span class="na">to</span><span class="o">(</span><span class="s">&quot;RoundingFlowlet&quot;</span><span class="o">)</span>
</pre></div>
</div>
<p>If you have multiple Flowlets of the same class, you can give them explicit names:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="o">.</span><span class="na">withFlowlets</span><span class="o">()</span>
  <span class="o">.</span><span class="na">add</span><span class="o">(</span><span class="s">&quot;random&quot;</span><span class="o">,</span> <span class="k">new</span> <span class="n">RandomGenerator</span><span class="o">())</span>
  <span class="o">.</span><span class="na">add</span><span class="o">(</span><span class="s">&quot;generator&quot;</span><span class="o">,</span> <span class="k">new</span> <span class="n">RandomGenerator</span><span class="o">())</span>
  <span class="o">.</span><span class="na">add</span><span class="o">(</span><span class="s">&quot;rounding&quot;</span><span class="o">,</span> <span class="k">new</span> <span class="n">RoundingFlowlet</span><span class="o">())</span>
<span class="o">.</span><span class="na">connect</span><span class="o">()</span>
  <span class="o">.</span><span class="na">from</span><span class="o">(</span><span class="s">&quot;random&quot;</span><span class="o">).</span><span class="na">to</span><span class="o">(</span><span class="s">&quot;rounding&quot;</span><span class="o">)</span>
</pre></div>
</div>
</div>
<div class="section" id="batch-execution">
<h4>Batch Execution<a class="headerlink" href="#batch-execution" title="Permalink to this headline">¶</a></h4>
<p>By default, a Flowlet processes a single data object at a time within a single
transaction. To increase throughput, you can also process a batch of data objects within
the same transaction:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="nd">@Batch</span><span class="o">(</span><span class="mi">100</span><span class="o">)</span>
<span class="nd">@ProcessInput</span>
<span class="kd">public</span> <span class="kt">void</span> <span class="nf">process</span><span class="o">(</span><span class="n">String</span> <span class="n">words</span><span class="o">)</span> <span class="o">{</span>
  <span class="o">...</span>
</pre></div>
</div>
<p>For the above batch example, the <strong>process</strong> method will be called up to 100 times per
transaction, with different data objects read from the input each time it is called.</p>
<p>If you are interested in knowing when a batch begins and ends, you can use an <strong>Iterator</strong>
as the method argument:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="nd">@Batch</span><span class="o">(</span><span class="mi">100</span><span class="o">)</span>
<span class="nd">@ProcessInput</span>
<span class="kd">public</span> <span class="kt">void</span> <span class="nf">process</span><span class="o">(</span><span class="n">Iterator</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;</span> <span class="n">words</span><span class="o">)</span> <span class="o">{</span>
  <span class="o">...</span>
</pre></div>
</div>
<p>In this case, the <strong>process</strong> will be called once per transaction and the <strong>Iterator</strong>
will contain up to 100 data objects read from the input.</p>
</div>
<div class="section" id="flowlets-and-instances">
<h4>Flowlets and Instances<a class="headerlink" href="#flowlets-and-instances" title="Permalink to this headline">¶</a></h4>
<p>You can have one or more instances of any given Flowlet, each consuming a disjoint
partition of each input. You can control the number of instances programmatically via the
<a class="reference internal" href="api.html#rest-scaling-flowlets"><em>REST interfaces</em></a> or via the CDAP Console. This enables you
to scale your application to meet capacity at runtime.</p>
<p>In the stand-alone CDAP, multiple Flowlet instances are run in threads, so in some cases
actual performance may not be improved. However, in the Distributed CDAP,
each Flowlet instance runs in its own Java Virtual Machine (JVM) with independent compute
resources. Scaling the number of Flowlets can improve performance and have a major impact
depending on your implementation.</p>
</div>
<div class="section" id="partitioning-strategies">
<h4>Partitioning Strategies<a class="headerlink" href="#partitioning-strategies" title="Permalink to this headline">¶</a></h4>
<p>As mentioned above, if you have multiple instances of a Flowlet the input queue is
partitioned among the Flowlets. The partitioning can occur in different ways, and each
Flowlet can specify one of these three partitioning strategies:</p>
<ul class="simple">
<li><strong>First-in first-out (FIFO):</strong> Default mode. In this mode, every Flowlet instance
receives the next available data object in the queue. However, since multiple consumers
may compete for the same data object, access to the queue must be synchronized. This may
not always be the most efficient strategy.</li>
<li><strong>Round-robin:</strong> With this strategy, the number of items is distributed evenly among the
instances. In general, round-robin is the most efficient partitioning. Though more
efficient than FIFO, it is not ideal when the application needs to group objects into
buckets according to business logic. In those cases, hash-based partitioning is
preferable.</li>
<li><strong>Hash-based:</strong> If the emitting Flowlet annotates each data object with a hash key, this
partitioning ensures that all objects of a given key are received by the same consumer
instance. This can be useful for aggregating by key, and can help reduce write conflicts.</li>
</ul>
<p>Suppose we have a Flowlet that counts words:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="kd">public</span> <span class="kd">class</span> <span class="nc">Counter</span> <span class="kd">extends</span> <span class="n">AbstractFlowlet</span> <span class="o">{</span>

  <span class="nd">@UseDataSet</span><span class="o">(</span><span class="s">&quot;wordCounts&quot;</span><span class="o">)</span>
  <span class="kd">private</span> <span class="n">KeyValueTable</span> <span class="n">wordCountsTable</span><span class="o">;</span>

  <span class="nd">@ProcessInput</span><span class="o">(</span><span class="s">&quot;wordOut&quot;</span><span class="o">)</span>
  <span class="kd">public</span> <span class="kt">void</span> <span class="nf">process</span><span class="o">(</span><span class="n">String</span> <span class="n">word</span><span class="o">)</span> <span class="o">{</span>
    <span class="k">this</span><span class="o">.</span><span class="na">wordCountsTable</span><span class="o">.</span><span class="na">increment</span><span class="o">(</span><span class="n">Bytes</span><span class="o">.</span><span class="na">toBytes</span><span class="o">(</span><span class="n">word</span><span class="o">),</span> <span class="mi">1L</span><span class="o">);</span>
  <span class="o">}</span>
<span class="o">}</span>
</pre></div>
</div>
<p>This Flowlet uses the default strategy of FIFO. To increase the throughput when this
Flowlet has many instances, we can specify round-robin partitioning:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="nd">@RoundRobin</span>
<span class="nd">@ProcessInput</span><span class="o">(</span><span class="s">&quot;wordOut&quot;</span><span class="o">)</span>
<span class="kd">public</span> <span class="kt">void</span> <span class="nf">process</span><span class="o">(</span><span class="n">String</span> <span class="n">word</span><span class="o">)</span> <span class="o">{</span>
  <span class="k">this</span><span class="o">.</span><span class="na">wordCountsTable</span><span class="o">.</span><span class="na">increment</span><span class="o">(</span><span class="n">Bytes</span><span class="o">.</span><span class="na">toBytes</span><span class="o">(</span><span class="n">word</span><span class="o">),</span> <span class="mi">1L</span><span class="o">);</span>
<span class="o">}</span>
</pre></div>
</div>
<p>Now, if we have three instances of this Flowlet, every instance will receive every third
word. For example, for the sequence of words in the sentence, “I scream, you scream, we
all scream for ice cream”:</p>
<ul class="simple">
<li>The first instance receives the words: <em>I scream scream cream</em></li>
<li>The second instance receives the words: <em>scream we for</em></li>
<li>The third instance receives the words: <em>you all ice</em></li>
</ul>
<p>The potential problem with this is that the first two instances might
both attempt to increment the counter for the word <em>scream</em> at the same time,
leading to a write conflict. To avoid conflicts, we can use hash-based partitioning:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="nd">@HashPartition</span><span class="o">(</span><span class="s">&quot;wordHash&quot;</span><span class="o">)</span>
<span class="nd">@ProcessInput</span><span class="o">(</span><span class="s">&quot;wordOut&quot;</span><span class="o">)</span>
<span class="kd">public</span> <span class="kt">void</span> <span class="nf">process</span><span class="o">(</span><span class="n">String</span> <span class="n">word</span><span class="o">)</span> <span class="o">{</span>
  <span class="k">this</span><span class="o">.</span><span class="na">wordCountsTable</span><span class="o">.</span><span class="na">increment</span><span class="o">(</span><span class="n">Bytes</span><span class="o">.</span><span class="na">toBytes</span><span class="o">(</span><span class="n">word</span><span class="o">),</span> <span class="mi">1L</span><span class="o">);</span>
<span class="o">}</span>
</pre></div>
</div>
<p>Now only one of the Flowlet instances will receive the word <em>scream</em>, and there can be no
more write conflicts. Note that in order to use hash-based partitioning, the emitting
Flowlet must annotate each data object with the partitioning key:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="nd">@Output</span><span class="o">(</span><span class="s">&quot;wordOut&quot;</span><span class="o">)</span>
<span class="kd">private</span> <span class="n">OutputEmitter</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;</span> <span class="n">wordOutput</span><span class="o">;</span>
<span class="o">...</span>
<span class="kd">public</span> <span class="kt">void</span> <span class="nf">process</span><span class="o">(</span><span class="n">StreamEvent</span> <span class="n">event</span><span class="o">)</span> <span class="o">{</span>
  <span class="o">...</span>
  <span class="c1">// emit the word with the partitioning key name &quot;wordHash&quot;</span>
  <span class="n">wordOutput</span><span class="o">.</span><span class="na">emit</span><span class="o">(</span><span class="n">word</span><span class="o">,</span> <span class="s">&quot;wordHash&quot;</span><span class="o">,</span> <span class="n">word</span><span class="o">.</span><span class="na">hashCode</span><span class="o">());</span>
<span class="o">}</span>
</pre></div>
</div>
<p>Note that the emitter must use the same name (&#8220;wordHash&#8221;) for the key that the consuming
Flowlet specifies as the partitioning key. If the output is connected to more than one
Flowlet, you can also annotate a data object with multiple hash keys—each consuming
Flowlet can then use different partitioning. This is useful if you want to aggregate by
multiple keys, such as counting purchases by product ID as well as by customer ID.</p>
<p>Partitioning can be combined with batch execution:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="nd">@Batch</span><span class="o">(</span><span class="mi">100</span><span class="o">)</span>
<span class="nd">@HashPartition</span><span class="o">(</span><span class="s">&quot;wordHash&quot;</span><span class="o">)</span>
<span class="nd">@ProcessInput</span><span class="o">(</span><span class="s">&quot;wordOut&quot;</span><span class="o">)</span>
<span class="kd">public</span> <span class="kt">void</span> <span class="nf">process</span><span class="o">(</span><span class="n">Iterator</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;</span> <span class="n">words</span><span class="o">)</span> <span class="o">{</span>
   <span class="o">...</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="mapreduce">
<span id="id8"></span><h2>MapReduce<a class="headerlink" href="#mapreduce" title="Permalink to this headline">¶</a></h2>
<p><strong>MapReduce</strong> is used to process data in batch. MapReduce jobs can be
written as in a conventional Hadoop system. Additionally, CDAP
<strong>Datasets</strong> can be accessed from MapReduce jobs as both input and
output.</p>
<p>To process data using MapReduce, specify <tt class="docutils literal"><span class="pre">addMapReduce()</span></tt> in your
Application specification:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="kd">public</span> <span class="kt">void</span> <span class="nf">configure</span><span class="o">()</span> <span class="o">{</span>
  <span class="o">...</span>
  <span class="n">addMapReduce</span><span class="o">(</span><span class="k">new</span> <span class="n">WordCountJob</span><span class="o">());</span>
</pre></div>
</div>
<p>You must implement the <tt class="docutils literal"><span class="pre">MapReduce</span></tt> interface, which requires the
implementation of three methods:</p>
<ul class="simple">
<li><tt class="docutils literal"><span class="pre">configure()</span></tt></li>
<li><tt class="docutils literal"><span class="pre">beforeSubmit()</span></tt></li>
<li><tt class="docutils literal"><span class="pre">onFinish()</span></tt></li>
</ul>
<div class="highlight-java"><div class="highlight"><pre><span class="kd">public</span> <span class="kd">class</span> <span class="nc">WordCountJob</span> <span class="kd">implements</span> <span class="n">MapReduce</span> <span class="o">{</span>
  <span class="nd">@Override</span>
  <span class="kd">public</span> <span class="n">MapReduceSpecification</span> <span class="nf">configure</span><span class="o">()</span> <span class="o">{</span>
    <span class="k">return</span> <span class="n">MapReduceSpecification</span><span class="o">.</span><span class="na">Builder</span><span class="o">.</span><span class="na">with</span><span class="o">()</span>
      <span class="o">.</span><span class="na">setName</span><span class="o">(</span><span class="s">&quot;WordCountJob&quot;</span><span class="o">)</span>
      <span class="o">.</span><span class="na">setDescription</span><span class="o">(</span><span class="s">&quot;Calculates word frequency&quot;</span><span class="o">)</span>
      <span class="o">.</span><span class="na">useInputDataSet</span><span class="o">(</span><span class="s">&quot;messages&quot;</span><span class="o">)</span>
      <span class="o">.</span><span class="na">useOutputDataSet</span><span class="o">(</span><span class="s">&quot;wordFrequency&quot;</span><span class="o">)</span>
      <span class="o">.</span><span class="na">build</span><span class="o">();</span>
  <span class="o">}</span>
</pre></div>
</div>
<p>The configure method is similar to the one found in Flows and
Applications. It defines the name and description of the MapReduce job.
You can also specify Datasets to be used as input or output for the job.</p>
<p>The <tt class="docutils literal"><span class="pre">beforeSubmit()</span></tt> method is invoked at runtime, before the
MapReduce job is executed. Through a passed instance of the
<tt class="docutils literal"><span class="pre">MapReduceContext</span></tt> you have access to the actual Hadoop job
configuration, as though you were running the MapReduce job directly on
Hadoop. For example, you can specify the Mapper and Reducer classes as
well as the intermediate data format:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="nd">@Override</span>
<span class="kd">public</span> <span class="kt">void</span> <span class="nf">beforeSubmit</span><span class="o">(</span><span class="n">MapReduceContext</span> <span class="n">context</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>
  <span class="n">Job</span> <span class="n">job</span> <span class="o">=</span> <span class="n">context</span><span class="o">.</span><span class="na">getHadoopJob</span><span class="o">();</span>
  <span class="n">job</span><span class="o">.</span><span class="na">setMapperClass</span><span class="o">(</span><span class="n">TokenizerMapper</span><span class="o">.</span><span class="na">class</span><span class="o">);</span>
  <span class="n">job</span><span class="o">.</span><span class="na">setReducerClass</span><span class="o">(</span><span class="n">IntSumReducer</span><span class="o">.</span><span class="na">class</span><span class="o">);</span>
  <span class="n">job</span><span class="o">.</span><span class="na">setMapOutputKeyClass</span><span class="o">(</span><span class="n">Text</span><span class="o">.</span><span class="na">class</span><span class="o">);</span>
  <span class="n">job</span><span class="o">.</span><span class="na">setMapOutputValueClass</span><span class="o">(</span><span class="n">IntWritable</span><span class="o">.</span><span class="na">class</span><span class="o">);</span>
<span class="o">}</span>
</pre></div>
</div>
<p>The <tt class="docutils literal"><span class="pre">onFinish()</span></tt> method is invoked after the MapReduce job has
finished. You could perform cleanup or send a notification of job
completion, if that was required. Because many MapReduce jobs do not
need this method, the <tt class="docutils literal"><span class="pre">AbstractMapReduce</span></tt> class provides a default
implementation that does nothing:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="nd">@Override</span>
<span class="kd">public</span> <span class="kt">void</span> <span class="nf">onFinish</span><span class="o">(</span><span class="kt">boolean</span> <span class="n">succeeded</span><span class="o">,</span> <span class="n">MapReduceContext</span> <span class="n">context</span><span class="o">)</span> <span class="o">{</span>
  <span class="c1">// do nothing</span>
<span class="o">}</span>
</pre></div>
</div>
<p>CDAP <tt class="docutils literal"><span class="pre">Mapper</span></tt> and <tt class="docutils literal"><span class="pre">Reducer</span></tt> implement <a class="reference external" href="http://hadoop.apache.org/docs/r2.3.0/api/org/apache/hadoop/mapreduce/package-summary.html">the standard Hadoop APIs</a>:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="kd">public</span> <span class="kd">static</span> <span class="kd">class</span> <span class="nc">TokenizerMapper</span>
    <span class="kd">extends</span> <span class="n">Mapper</span><span class="o">&lt;</span><span class="kt">byte</span><span class="o">[],</span> <span class="kt">byte</span><span class="o">[],</span> <span class="n">Text</span><span class="o">,</span> <span class="n">IntWritable</span><span class="o">&gt;</span> <span class="o">{</span>

  <span class="kd">private</span> <span class="kd">final</span> <span class="kd">static</span> <span class="n">IntWritable</span> <span class="n">one</span> <span class="o">=</span> <span class="k">new</span> <span class="n">IntWritable</span><span class="o">(</span><span class="mi">1</span><span class="o">);</span>
  <span class="kd">private</span> <span class="n">Text</span> <span class="n">word</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Text</span><span class="o">();</span>
  <span class="kd">public</span> <span class="kt">void</span> <span class="nf">map</span><span class="o">(</span><span class="kt">byte</span><span class="o">[]</span> <span class="n">key</span><span class="o">,</span> <span class="kt">byte</span><span class="o">[]</span> <span class="n">value</span><span class="o">,</span> <span class="n">Context</span> <span class="n">context</span><span class="o">)</span>
      <span class="kd">throws</span> <span class="n">IOException</span><span class="o">,</span> <span class="n">InterruptedException</span> <span class="o">{</span>
    <span class="n">StringTokenizer</span> <span class="n">itr</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StringTokenizer</span><span class="o">(</span><span class="n">Bytes</span><span class="o">.</span><span class="na">toString</span><span class="o">(</span><span class="n">value</span><span class="o">));</span>
    <span class="k">while</span> <span class="o">(</span><span class="n">itr</span><span class="o">.</span><span class="na">hasMoreTokens</span><span class="o">())</span> <span class="o">{</span>
      <span class="n">word</span><span class="o">.</span><span class="na">set</span><span class="o">(</span><span class="n">itr</span><span class="o">.</span><span class="na">nextToken</span><span class="o">());</span>
      <span class="n">context</span><span class="o">.</span><span class="na">write</span><span class="o">(</span><span class="n">word</span><span class="o">,</span> <span class="n">one</span><span class="o">);</span>
    <span class="o">}</span>
  <span class="o">}</span>
<span class="o">}</span>

<span class="kd">public</span> <span class="kd">static</span> <span class="kd">class</span> <span class="nc">IntSumReducer</span>
    <span class="kd">extends</span> <span class="n">Reducer</span><span class="o">&lt;</span><span class="n">Text</span><span class="o">,</span> <span class="n">IntWritable</span><span class="o">,</span> <span class="kt">byte</span><span class="o">[],</span> <span class="kt">byte</span><span class="o">[]&gt;</span> <span class="o">{</span>

  <span class="kd">public</span> <span class="kt">void</span> <span class="nf">reduce</span><span class="o">(</span><span class="n">Text</span> <span class="n">key</span><span class="o">,</span> <span class="n">Iterable</span><span class="o">&lt;</span><span class="n">IntWritable</span><span class="o">&gt;</span> <span class="n">values</span><span class="o">,</span> <span class="n">Context</span> <span class="n">context</span><span class="o">)</span>
      <span class="kd">throws</span> <span class="n">IOException</span><span class="o">,</span> <span class="n">InterruptedException</span> <span class="o">{</span>
    <span class="kt">int</span> <span class="n">sum</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span>
    <span class="k">for</span> <span class="o">(</span><span class="n">IntWritable</span> <span class="n">val</span> <span class="o">:</span> <span class="n">values</span><span class="o">)</span> <span class="o">{</span>
      <span class="n">sum</span> <span class="o">+=</span> <span class="n">val</span><span class="o">.</span><span class="na">get</span><span class="o">();</span>
    <span class="o">}</span>
    <span class="n">context</span><span class="o">.</span><span class="na">write</span><span class="o">(</span><span class="n">key</span><span class="o">.</span><span class="na">copyBytes</span><span class="o">(),</span> <span class="n">Bytes</span><span class="o">.</span><span class="na">toBytes</span><span class="o">(</span><span class="n">sum</span><span class="o">));</span>
  <span class="o">}</span>
<span class="o">}</span>
</pre></div>
</div>
<div class="section" id="mapreduce-and-datasets">
<h3>MapReduce and Datasets<a class="headerlink" href="#mapreduce-and-datasets" title="Permalink to this headline">¶</a></h3>
<p>Both CDAP <tt class="docutils literal"><span class="pre">Mapper</span></tt> and <tt class="docutils literal"><span class="pre">Reducer</span></tt> can directly read
from a Dataset or write to a Dataset similar to the way a Flowlet or Service can.</p>
<p>To access a Dataset directly in Mapper or Reducer, you need (1) a
declaration and (2) an injection:</p>
<ol class="arabic">
<li><p class="first">Declare the Dataset in the MapReduce job’s configure() method.
For example, to have access to a Dataset named <em>catalog</em>:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="kd">public</span> <span class="kd">class</span> <span class="nc">MyMapReduceJob</span> <span class="kd">implements</span> <span class="n">MapReduce</span> <span class="o">{</span>
  <span class="nd">@Override</span>
  <span class="kd">public</span> <span class="n">MapReduceSpecification</span> <span class="nf">configure</span><span class="o">()</span> <span class="o">{</span>
    <span class="k">return</span> <span class="n">MapReduceSpecification</span><span class="o">.</span><span class="na">Builder</span><span class="o">.</span><span class="na">with</span><span class="o">()</span>
      <span class="o">...</span>
      <span class="o">.</span><span class="na">useDataSet</span><span class="o">(</span><span class="s">&quot;catalog&quot;</span><span class="o">)</span>
      <span class="o">...</span>
</pre></div>
</div>
</li>
<li><p class="first">Inject the Dataset into the mapper or reducer that uses it:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="kd">public</span> <span class="kd">static</span> <span class="kd">class</span> <span class="nc">CatalogJoinMapper</span> <span class="kd">extends</span> <span class="n">Mapper</span><span class="o">&lt;</span><span class="kt">byte</span><span class="o">[],</span> <span class="n">Purchase</span><span class="o">,</span> <span class="o">...&gt;</span> <span class="o">{</span>
  <span class="nd">@UseDataSet</span><span class="o">(</span><span class="s">&quot;catalog&quot;</span><span class="o">)</span>
  <span class="kd">private</span> <span class="n">ProductCatalog</span> <span class="n">catalog</span><span class="o">;</span>

  <span class="nd">@Override</span>
  <span class="kd">public</span> <span class="kt">void</span> <span class="nf">map</span><span class="o">(</span><span class="kt">byte</span><span class="o">[]</span> <span class="n">key</span><span class="o">,</span> <span class="n">Purchase</span> <span class="n">purchase</span><span class="o">,</span> <span class="n">Context</span> <span class="n">context</span><span class="o">)</span>
      <span class="kd">throws</span> <span class="n">IOException</span><span class="o">,</span> <span class="n">InterruptedException</span> <span class="o">{</span>
    <span class="c1">// join with catalog by product ID</span>
    <span class="n">Product</span> <span class="n">product</span> <span class="o">=</span> <span class="n">catalog</span><span class="o">.</span><span class="na">read</span><span class="o">(</span><span class="n">purchase</span><span class="o">.</span><span class="na">getProductId</span><span class="o">());</span>
    <span class="o">...</span>
  <span class="o">}</span>
</pre></div>
</div>
</li>
</ol>
</div>
</div>
<div class="section" id="workflow">
<span id="workflows"></span><h2>Workflow<a class="headerlink" href="#workflow" title="Permalink to this headline">¶</a></h2>
<p><strong>Workflows</strong> are used to execute a series of <a class="reference internal" href="#mapreduce">MapReduce</a> jobs. A
Workflow is given a sequence of jobs that follow each other, with an
optional schedule to run the Workflow periodically. On successful
execution of a job, the control is transferred to the next job in
sequence until the last job in the sequence is executed. On failure, the
execution is stopped at the failed job and no subsequent jobs in the
sequence are executed.</p>
<p>To process one or more MapReduce jobs in sequence, specify
<tt class="docutils literal"><span class="pre">addWorkflow()</span></tt> in your application:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="kd">public</span> <span class="kt">void</span> <span class="nf">configure</span><span class="o">()</span> <span class="o">{</span>
  <span class="o">...</span>
  <span class="n">addWorkflow</span><span class="o">(</span><span class="k">new</span> <span class="n">PurchaseHistoryWorkflow</span><span class="o">());</span>
</pre></div>
</div>
<p>You&#8217;ll then implement the <tt class="docutils literal"><span class="pre">Workflow</span></tt> interface, which requires the
<tt class="docutils literal"><span class="pre">configure()</span></tt> method. From within <tt class="docutils literal"><span class="pre">configure</span></tt>, call the
<tt class="docutils literal"><span class="pre">addSchedule()</span></tt> method to run a WorkFlow job periodically:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="kd">public</span> <span class="kd">static</span> <span class="kd">class</span> <span class="nc">PurchaseHistoryWorkflow</span> <span class="kd">implements</span> <span class="n">Workflow</span> <span class="o">{</span>

  <span class="nd">@Override</span>
  <span class="kd">public</span> <span class="n">WorkflowSpecification</span> <span class="nf">configure</span><span class="o">()</span> <span class="o">{</span>
    <span class="k">return</span> <span class="n">WorkflowSpecification</span><span class="o">.</span><span class="na">Builder</span><span class="o">.</span><span class="na">with</span><span class="o">()</span>
      <span class="o">.</span><span class="na">setName</span><span class="o">(</span><span class="s">&quot;PurchaseHistoryWorkflow&quot;</span><span class="o">)</span>
      <span class="o">.</span><span class="na">setDescription</span><span class="o">(</span><span class="s">&quot;PurchaseHistoryWorkflow description&quot;</span><span class="o">)</span>
      <span class="o">.</span><span class="na">startWith</span><span class="o">(</span><span class="k">new</span> <span class="n">PurchaseHistoryBuilder</span><span class="o">())</span>
      <span class="o">.</span><span class="na">last</span><span class="o">(</span><span class="k">new</span> <span class="n">PurchaseTrendBuilder</span><span class="o">())</span>
      <span class="o">.</span><span class="na">addSchedule</span><span class="o">(</span><span class="k">new</span> <span class="n">DefaultSchedule</span><span class="o">(</span><span class="s">&quot;FiveMinuteSchedule&quot;</span><span class="o">,</span> <span class="s">&quot;Run every 5 minutes&quot;</span><span class="o">,</span>
                   <span class="s">&quot;0/5 * * * *&quot;</span><span class="o">,</span> <span class="n">Schedule</span><span class="o">.</span><span class="na">Action</span><span class="o">.</span><span class="na">START</span><span class="o">))</span>
      <span class="o">.</span><span class="na">build</span><span class="o">();</span>
  <span class="o">}</span>
<span class="o">}</span>
</pre></div>
</div>
<p>If there is only one MapReduce job to be run as a part of a WorkFlow,
use the <tt class="docutils literal"><span class="pre">onlyWith()</span></tt> method after <tt class="docutils literal"><span class="pre">setDescription()</span></tt> when building
the Workflow:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="kd">public</span> <span class="kd">static</span> <span class="kd">class</span> <span class="nc">PurchaseHistoryWorkflow</span> <span class="kd">implements</span> <span class="n">Workflow</span> <span class="o">{</span>

  <span class="nd">@Override</span>
  <span class="kd">public</span> <span class="n">WorkflowSpecification</span> <span class="nf">configure</span><span class="o">()</span> <span class="o">{</span>
    <span class="k">return</span> <span class="n">WorkflowSpecification</span><span class="o">.</span><span class="na">Builder</span><span class="o">.</span><span class="na">with</span><span class="o">()</span> <span class="o">.</span><span class="na">setName</span><span class="o">(</span><span class="s">&quot;PurchaseHistoryWorkflow&quot;</span><span class="o">)</span>
      <span class="o">.</span><span class="na">setDescription</span><span class="o">(</span><span class="s">&quot;PurchaseHistoryWorkflow description&quot;</span><span class="o">)</span>
      <span class="o">.</span><span class="na">onlyWith</span><span class="o">(</span><span class="k">new</span> <span class="n">PurchaseHistoryBuilder</span><span class="o">())</span>
      <span class="o">.</span><span class="na">addSchedule</span><span class="o">(</span><span class="k">new</span> <span class="n">DefaultSchedule</span><span class="o">(</span><span class="s">&quot;FiveMinuteSchedule&quot;</span><span class="o">,</span> <span class="s">&quot;Run every 5 minutes&quot;</span><span class="o">,</span>
                   <span class="s">&quot;0/5 * * * *&quot;</span><span class="o">,</span> <span class="n">Schedule</span><span class="o">.</span><span class="na">Action</span><span class="o">.</span><span class="na">START</span><span class="o">))</span>
      <span class="o">.</span><span class="na">build</span><span class="o">();</span>
  <span class="o">}</span>
<span class="o">}</span>
</pre></div>
</div>
</div>
<div class="section" id="spark-beta-standalone-cdap-only">
<span id="spark"></span><h2>Spark (Beta, Standalone CDAP only)<a class="headerlink" href="#spark-beta-standalone-cdap-only" title="Permalink to this headline">¶</a></h2>
<p><strong>Spark</strong> is used for in-memory cluster computing. It lets you load large sets of data into memory and query them
repeatedly. This makes it suitable for both iterative and interactive programs. Similar to MapReduce,
Spark can access <strong>Datasets</strong> as both input and output. Spark programs in CDAP can be written in either Java or Scala.</p>
<p>In the current release, Spark is supported only in the Standalone CDAP.</p>
<p>To process data using Spark, specify <tt class="docutils literal"><span class="pre">addSpark()</span></tt> in your Application specification:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="kd">public</span> <span class="kt">void</span> <span class="nf">configure</span><span class="o">()</span> <span class="o">{</span>
  <span class="o">...</span>
    <span class="n">addSpark</span><span class="o">(</span><span class="k">new</span> <span class="n">WordCountProgram</span><span class="o">());</span>
</pre></div>
</div>
<p>You must implement the <tt class="docutils literal"><span class="pre">Spark</span></tt> interface, which requires the
implementation of three methods:</p>
<ul class="simple">
<li><tt class="docutils literal"><span class="pre">configure()</span></tt></li>
<li><tt class="docutils literal"><span class="pre">beforeSubmit()</span></tt></li>
<li><tt class="docutils literal"><span class="pre">onFinish()</span></tt></li>
</ul>
<div class="highlight-java"><div class="highlight"><pre><span class="kd">public</span> <span class="kd">class</span> <span class="nc">WordCountProgram</span> <span class="kd">implements</span> <span class="n">Spark</span> <span class="o">{</span>
  <span class="nd">@Override</span>
  <span class="kd">public</span> <span class="n">SparkSpecification</span> <span class="nf">configure</span><span class="o">()</span> <span class="o">{</span>
    <span class="k">return</span> <span class="n">SparkSpecification</span><span class="o">.</span><span class="na">Builder</span><span class="o">.</span><span class="na">with</span><span class="o">()</span>
      <span class="o">.</span><span class="na">setName</span><span class="o">(</span><span class="s">&quot;WordCountProgram&quot;</span><span class="o">)</span>
      <span class="o">.</span><span class="na">setDescription</span><span class="o">(</span><span class="s">&quot;Calculates word frequency&quot;</span><span class="o">)</span>
      <span class="o">.</span><span class="na">setMainClassName</span><span class="o">(</span><span class="s">&quot;com.example.WordCounter&quot;</span><span class="o">)</span>
      <span class="o">.</span><span class="na">build</span><span class="o">();</span>
  <span class="o">}</span>
</pre></div>
</div>
<p>The configure method is similar to the one found in Flows and
MapReduce jobs. It defines the name, description, and the class containing the main method of a Spark program.</p>
<p>The <tt class="docutils literal"><span class="pre">beforeSubmit()</span></tt> method is invoked at runtime, before the
Spark program is executed. Because many Spark programs do not
need this method, the <tt class="docutils literal"><span class="pre">AbstractSpark</span></tt> class provides a default
implementation that does nothing:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="nd">@Override</span>
<span class="kd">public</span> <span class="kt">void</span> <span class="nf">beforeSubmit</span><span class="o">(</span><span class="n">SparkContext</span> <span class="n">context</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>
  <span class="c1">// Do nothing by default</span>
<span class="o">}</span>
</pre></div>
</div>
<p>The <tt class="docutils literal"><span class="pre">onFinish()</span></tt> method is invoked after the Spark program has
finished. You could perform cleanup or send a notification of program
completion, if that was required. Like <tt class="docutils literal"><span class="pre">beforeSubmit()</span></tt>, since many Spark programs do not
need this method, the <tt class="docutils literal"><span class="pre">AbstractSpark</span></tt> class also provides a default
implementation for this method that does nothing:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="nd">@Override</span>
<span class="kd">public</span> <span class="kt">void</span> <span class="nf">onFinish</span><span class="o">(</span><span class="kt">boolean</span> <span class="n">succeeded</span><span class="o">,</span> <span class="n">SparkContext</span> <span class="n">context</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>
  <span class="c1">// Do nothing by default</span>
<span class="o">}</span>
</pre></div>
</div>
<div class="section" id="cdap-sparkcontext">
<h3>CDAP SparkContext<a class="headerlink" href="#cdap-sparkcontext" title="Permalink to this headline">¶</a></h3>
<p>CDAP provides its own <tt class="docutils literal"><span class="pre">SparkContext</span></tt> which is needed to access <strong>Datasets</strong>.</p>
<p>CDAP Spark programs must implement either <tt class="docutils literal"><span class="pre">JavaSparkProgram</span></tt> or <tt class="docutils literal"><span class="pre">ScalaSparkProgram</span></tt>,
depending upon the language (Java or Scala) in which the program is written. You can also access the Spark&#8217;s
<tt class="docutils literal"><span class="pre">SparkContext</span></tt> (for Scala programs) and <tt class="docutils literal"><span class="pre">JavaSparkContext</span></tt> (for Java programs) in your CDAP Spark program by calling
<tt class="docutils literal"><span class="pre">getOriginalSparkContext()</span></tt> on CDAP <tt class="docutils literal"><span class="pre">SparkContext</span></tt>.</p>
<ul>
<li><p class="first">Java:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="kd">public</span> <span class="kd">class</span> <span class="nc">MyJavaSparkProgram</span> <span class="kd">implements</span> <span class="n">JavaSparkProgram</span> <span class="o">{</span>
  <span class="nd">@Override</span>
  <span class="kd">public</span> <span class="kt">void</span> <span class="nf">run</span><span class="o">(</span><span class="n">SparkContext</span> <span class="n">sparkContext</span><span class="o">)</span> <span class="o">{</span>
    <span class="n">JavaSparkContext</span> <span class="n">originalSparkContext</span> <span class="o">=</span> <span class="n">sparkContext</span><span class="o">.</span><span class="na">originalSparkContext</span><span class="o">();</span>
      <span class="o">...</span>
  <span class="o">}</span>
<span class="o">}</span>
</pre></div>
</div>
</li>
<li><p class="first">Scala:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="kd">class</span> <span class="nc">MyScalaSparkProgram</span> <span class="kd">implements</span> <span class="n">ScalaSparkProgram</span> <span class="o">{</span>
  <span class="n">override</span> <span class="n">def</span> <span class="nf">run</span><span class="o">(</span><span class="nl">sparkContext:</span> <span class="n">SparkContext</span><span class="o">)</span> <span class="o">{</span>
    <span class="n">val</span> <span class="n">originalSparkContext</span> <span class="o">=</span> <span class="n">sparkContext</span><span class="o">.</span><span class="na">originalSparkContext</span><span class="o">();</span>
      <span class="o">...</span>
    <span class="o">}</span>
<span class="o">}</span>
</pre></div>
</div>
</li>
</ul>
</div>
<div class="section" id="spark-and-datasets">
<h3>Spark and Datasets<a class="headerlink" href="#spark-and-datasets" title="Permalink to this headline">¶</a></h3>
<p>Spark programs in CDAP can directly access <strong>Dataset</strong> similar to the way a MapReduce or
Procedure can. These programs can create Spark&#8217;s Resilient Distributed Dataset (RDD) by reading a Datasets and also
write RDD to a Dataset.</p>
<ul>
<li><p class="first">Creating an RDD from Dataset</p>
<ul class="simple">
<li>Java:</li>
</ul>
<div class="highlight-java"><div class="highlight"><pre><span class="n">JavaPairRDD</span><span class="o">&lt;</span><span class="kt">byte</span><span class="o">[],</span> <span class="n">Purchase</span><span class="o">&gt;</span> <span class="n">purchaseRDD</span> <span class="o">=</span> <span class="n">sparkContext</span><span class="o">.</span><span class="na">readFromDataset</span><span class="o">(</span><span class="s">&quot;purchases&quot;</span><span class="o">,</span>
                                                                          <span class="kt">byte</span><span class="o">[].</span><span class="na">class</span><span class="o">,</span>
                                                                          <span class="n">Purchase</span><span class="o">.</span><span class="na">class</span><span class="o">);</span>
</pre></div>
</div>
<ul class="simple">
<li>Scala:</li>
</ul>
<div class="highlight-java"><div class="highlight"><pre><span class="n">val</span> <span class="nl">purchaseRDD:</span> <span class="n">RDD</span><span class="o">[(</span><span class="n">Array</span><span class="o">[</span><span class="n">Byte</span><span class="o">],</span> <span class="n">Purchase</span><span class="o">)]</span> <span class="o">=</span> <span class="n">sparkContext</span><span class="o">.</span><span class="na">readFromDataset</span><span class="o">(</span><span class="s">&quot;purchases&quot;</span><span class="o">,</span>
                                                                              <span class="n">classOf</span><span class="o">[</span><span class="n">Array</span><span class="o">[</span><span class="n">Byte</span><span class="o">]],</span>
                                                                              <span class="n">classOf</span><span class="o">[</span><span class="n">Purchase</span><span class="o">]);</span>
</pre></div>
</div>
</li>
<li><p class="first">Writing an RDD to Dataset</p>
<ul class="simple">
<li>Java:</li>
</ul>
<div class="highlight-java"><div class="highlight"><pre><span class="n">sparkContext</span><span class="o">.</span><span class="na">writeToDataset</span><span class="o">(</span><span class="n">purchaseRDD</span><span class="o">,</span> <span class="s">&quot;purchases&quot;</span><span class="o">,</span> <span class="kt">byte</span><span class="o">[].</span><span class="na">class</span><span class="o">,</span> <span class="n">Purchase</span><span class="o">.</span><span class="na">class</span><span class="o">);</span>
</pre></div>
</div>
<ul class="simple">
<li>Scala:</li>
</ul>
<div class="highlight-java"><div class="highlight"><pre><span class="n">sparkContext</span><span class="o">.</span><span class="na">writeToDataset</span><span class="o">(</span><span class="n">purchaseRDD</span><span class="o">,</span> <span class="s">&quot;purchases&quot;</span><span class="o">,</span> <span class="n">classOf</span><span class="o">[</span><span class="n">Array</span><span class="o">[</span><span class="n">Byte</span><span class="o">]],</span> <span class="n">classOf</span><span class="o">[</span><span class="n">Purchase</span><span class="o">])</span>
</pre></div>
</div>
</li>
</ul>
</div>
</div>
<div class="section" id="services">
<span id="user-services"></span><h2>Services<a class="headerlink" href="#services" title="Permalink to this headline">¶</a></h2>
<p>Services can be run in a Cask Data Application Platform (CDAP) Application to serve data to external clients.
Similar to Flows, Services run in containers and the number of running service instances can be dynamically scaled.
Developers can implement Custom Services to interface with a legacy system and perform additional processing beyond
the CDAP processing paradigms. Examples could include running an IP-to-Geo lookup and serving user-profiles.</p>
<p>Custom Services lifecycle can be controlled via the CDAP Console or by using the
<a class="reference internal" href="api.html#client-api"><em>CDAP Java Client API</em></a> or <a class="reference internal" href="api.html#restful-api"><em>CDAP RESTful HTTP API</em></a>.</p>
<p>Services are implemented by extending <tt class="docutils literal"><span class="pre">AbstractService</span></tt>, which consists of <tt class="docutils literal"><span class="pre">HttpServiceHandler</span></tt> s to serve requests.</p>
<p>You can add Services to your application by calling the <tt class="docutils literal"><span class="pre">addService</span></tt> method in the
Application&#8217;s <tt class="docutils literal"><span class="pre">configure</span></tt> method:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="kd">public</span> <span class="kd">class</span> <span class="nc">AnalyticsApp</span> <span class="kd">extends</span> <span class="n">AbstractApplication</span> <span class="o">{</span>
  <span class="nd">@Override</span>
  <span class="kd">public</span> <span class="kt">void</span> <span class="nf">configure</span><span class="o">()</span> <span class="o">{</span>
    <span class="n">setName</span><span class="o">(</span><span class="s">&quot;AnalyticsApp&quot;</span><span class="o">);</span>
    <span class="n">setDescription</span><span class="o">(</span><span class="s">&quot;Application for generating mobile analytics&quot;</span><span class="o">);</span>
    <span class="n">addStream</span><span class="o">(</span><span class="k">new</span> <span class="n">Stream</span><span class="o">(</span><span class="s">&quot;event&quot;</span><span class="o">));</span>
    <span class="n">addFlow</span><span class="o">(</span><span class="k">new</span> <span class="n">EventProcessingFlow</span><span class="o">());</span>
    <span class="o">...</span>
    <span class="n">addService</span><span class="o">(</span><span class="k">new</span> <span class="n">IPGeoLookupService</span><span class="o">());</span>
    <span class="n">addService</span><span class="o">(</span><span class="k">new</span> <span class="n">UserLookupService</span><span class="o">());</span>
    <span class="o">...</span>
  <span class="o">}</span>
<span class="o">}</span>
</pre></div>
</div>
<div class="highlight-java"><div class="highlight"><pre><span class="kd">public</span> <span class="kd">class</span> <span class="nc">IPGeoLookupService</span> <span class="kd">extends</span> <span class="n">AbstractService</span> <span class="o">{</span>

  <span class="nd">@Override</span>
  <span class="kd">protected</span> <span class="kt">void</span> <span class="nf">configure</span><span class="o">()</span> <span class="o">{</span>
    <span class="n">setName</span><span class="o">(</span><span class="s">&quot;IpGeoLookupService&quot;</span><span class="o">);</span>
    <span class="n">setDescription</span><span class="o">(</span><span class="s">&quot;Service to lookup locations of IP addresses.&quot;</span><span class="o">);</span>
    <span class="n">useDataset</span><span class="o">(</span><span class="s">&quot;IPGeoTable&quot;</span><span class="o">);</span>
    <span class="n">addHandler</span><span class="o">(</span><span class="k">new</span> <span class="n">IPGeoLookupHandler</span><span class="o">());</span>
  <span class="o">}</span>
<span class="o">}</span>
</pre></div>
</div>
<div class="section" id="service-handlers">
<h3>Service Handlers<a class="headerlink" href="#service-handlers" title="Permalink to this headline">¶</a></h3>
<p><tt class="docutils literal"><span class="pre">ServiceHandler</span></tt> s are used to handle and serve HTTP requests.</p>
<p>You add handlers to your Service by calling the <tt class="docutils literal"><span class="pre">addHandler</span></tt> method in the Service&#8217;s <tt class="docutils literal"><span class="pre">configure</span></tt> method.</p>
<p>To use a Dataset within a handler, specify the Dataset by calling the <tt class="docutils literal"><span class="pre">useDataset</span></tt> method in the Service&#8217;s
<tt class="docutils literal"><span class="pre">configure</span></tt> method and include the <tt class="docutils literal"><span class="pre">&#64;UseDataSet</span></tt> annotation in the handler to obtain an instance of the Dataset.
Each request to a method is committed as a single transaction.</p>
<div class="highlight-java"><div class="highlight"><pre><span class="kd">public</span> <span class="kd">class</span> <span class="nc">IPGeoLookupHandler</span> <span class="kd">extends</span> <span class="n">AbstractHttpServiceHandler</span> <span class="o">{</span>
  <span class="nd">@UseDataSet</span><span class="o">(</span><span class="s">&quot;IPGeoTable&quot;</span><span class="o">)</span>
  <span class="n">Table</span> <span class="n">table</span><span class="o">;</span>

  <span class="nd">@Path</span><span class="o">(</span><span class="s">&quot;lookup/{ip}&quot;</span><span class="o">)</span>
  <span class="nd">@GET</span>
  <span class="kd">public</span> <span class="kt">void</span> <span class="nf">lookup</span><span class="o">(</span><span class="n">HttpServiceRequest</span> <span class="n">request</span><span class="o">,</span> <span class="n">HttpServiceResponder</span> <span class="n">responder</span><span class="o">,</span>
                                                    <span class="nd">@PathParam</span><span class="o">(</span><span class="s">&quot;ip&quot;</span><span class="o">)</span> <span class="n">String</span> <span class="n">ip</span><span class="o">)</span> <span class="o">{</span>
    <span class="c1">// ...</span>
    <span class="n">responder</span><span class="o">.</span><span class="na">sendString</span><span class="o">(</span><span class="mi">200</span><span class="o">,</span> <span class="n">location</span><span class="o">,</span> <span class="n">Charsets</span><span class="o">.</span><span class="na">UTF_8</span><span class="o">);</span>
  <span class="o">}</span>
<span class="o">}</span>
</pre></div>
</div>
</div>
<div class="section" id="service-discovery">
<h3>Service Discovery<a class="headerlink" href="#service-discovery" title="Permalink to this headline">¶</a></h3>
<p>Services announce the host and port they are running on so that they can be discovered by—and provide
access to—other programs.</p>
<p>Service are announced using the name passed in the <tt class="docutils literal"><span class="pre">configure</span></tt> method. The <em>application name</em>, <em>service id</em>, and
<em>hostname</em> required for registering the Service are automatically obtained.</p>
<p>The Service can then be discovered in Flows, Procedures, MapReduce jobs, and other Services using
appropriate program contexts. You may also access Services in a different Application
by specifying the Application name in the <tt class="docutils literal"><span class="pre">getServiceURL</span></tt> call.</p>
<p>For example, in Flows:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="kd">public</span> <span class="kd">class</span> <span class="nc">GeoFlowlet</span> <span class="kd">extends</span> <span class="n">AbstractFlowlet</span> <span class="o">{</span>

  <span class="c1">// URL for IPGeoLookupService</span>
  <span class="kd">private</span> <span class="n">URL</span> <span class="n">serviceURL</span><span class="o">;</span>

  <span class="c1">// URL for SecurityService in SecurityApplication</span>
  <span class="kd">private</span> <span class="n">URL</span> <span class="n">securityURL</span><span class="o">;</span>

  <span class="nd">@ProcessInput</span>
  <span class="kd">public</span> <span class="kt">void</span> <span class="nf">process</span><span class="o">(</span><span class="n">String</span> <span class="n">ip</span><span class="o">)</span> <span class="o">{</span>
    <span class="c1">// Get URL for Service in same Application</span>
    <span class="n">serviceURL</span> <span class="o">=</span> <span class="n">getContext</span><span class="o">().</span><span class="na">getServiceURL</span><span class="o">(</span><span class="s">&quot;IPGeoLookupService&quot;</span><span class="o">);</span>

    <span class="c1">// Get URL for Service in a different Application</span>
    <span class="n">securityURL</span> <span class="o">=</span> <span class="n">getContext</span><span class="o">().</span><span class="na">getServiceURL</span><span class="o">(</span><span class="s">&quot;SecurityApplication&quot;</span><span class="o">,</span> <span class="s">&quot;SecurityService&quot;</span><span class="o">);</span>

    <span class="c1">// Access the IPGeoLookupService using its URL</span>
    <span class="n">URLConnection</span> <span class="n">connection</span> <span class="o">=</span> <span class="k">new</span> <span class="n">URL</span><span class="o">(</span><span class="n">serviceURL</span><span class="o">,</span> <span class="n">String</span><span class="o">.</span><span class="na">format</span><span class="o">(</span><span class="s">&quot;lookup/%s&quot;</span><span class="o">,</span> <span class="n">ip</span><span class="o">)).</span><span class="na">openConnection</span><span class="o">();</span>
    <span class="n">BufferedReader</span> <span class="n">reader</span> <span class="o">=</span> <span class="k">new</span> <span class="n">BufferedReader</span><span class="o">(</span><span class="k">new</span> <span class="n">InputStreamReader</span><span class="o">(</span><span class="n">connection</span><span class="o">.</span><span class="na">getInputStream</span><span class="o">()));</span>
    <span class="o">...</span>
  <span class="o">}</span>
<span class="o">}</span>
</pre></div>
</div>
</div>
<div class="section" id="procedures">
<span id="id9"></span><h3>Procedures<a class="headerlink" href="#procedures" title="Permalink to this headline">¶</a></h3>
<p>To query CDAP and its Datasets and retrieve results, you can use Procedures.</p>
<p>Procedures allow you to make synchronous calls into CDAP from an external system
and perform server-side processing on-demand, similar to a stored procedure in a
traditional database.</p>
<p>Procedures are typically used to post-process data at query time. This
post-processing can include filtering, aggregating, or joins over
multiple Datasets—in fact, a Procedure can perform all the same
operations as a Flowlet with the same consistency and durability
guarantees. They are deployed into the same pool of application
containers as Flows, and you can run multiple instances to increase the
throughput of requests.</p>
<p>A Procedure implements and exposes a very simple API: a method name
(String) and arguments (map of Strings). This implementation is then
bound to a REST endpoint and can be called from any external system.</p>
<p>To create a Procedure you implement the <tt class="docutils literal"><span class="pre">Procedure</span></tt> interface, or more
conveniently, extend the <tt class="docutils literal"><span class="pre">AbstractProcedure</span></tt> class.</p>
<p>A Procedure is configured and initialized similarly to a Flowlet, but
instead of a process method you’ll define a handler method. Upon
external call, the handler method receives the request and sends a
response.</p>
<p>The initialize method is called when the Procedure handler is created.
It is not created until the first request is received for it.</p>
<p>The most generic way to send a response is to obtain a
<tt class="docutils literal"><span class="pre">Writer</span></tt> and stream out the response as bytes. Make sure to close the
<tt class="docutils literal"><span class="pre">Writer</span></tt> when you are done:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">static</span> <span class="n">co</span><span class="o">.</span><span class="na">cask</span><span class="o">.</span><span class="na">cdap</span><span class="o">.</span><span class="na">api</span><span class="o">.</span><span class="na">procedure</span><span class="o">.</span><span class="na">ProcedureResponse</span><span class="o">.</span><span class="na">Code</span><span class="o">.</span><span class="na">SUCCESS</span><span class="o">;</span>
<span class="o">...</span>
<span class="kd">class</span> <span class="nc">HelloWorld</span> <span class="kd">extends</span> <span class="n">AbstractProcedure</span> <span class="o">{</span>

  <span class="nd">@Handle</span><span class="o">(</span><span class="s">&quot;hello&quot;</span><span class="o">)</span>
  <span class="kd">public</span> <span class="kt">void</span> <span class="nf">wave</span><span class="o">(</span><span class="n">ProcedureRequest</span> <span class="n">request</span><span class="o">,</span>
                   <span class="n">ProcedureResponder</span> <span class="n">responder</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">IOException</span> <span class="o">{</span>
    <span class="n">String</span> <span class="n">hello</span> <span class="o">=</span> <span class="s">&quot;Hello &quot;</span> <span class="o">+</span> <span class="n">request</span><span class="o">.</span><span class="na">getArgument</span><span class="o">(</span><span class="s">&quot;who&quot;</span><span class="o">);</span>
    <span class="n">ProcedureResponse</span><span class="o">.</span><span class="na">Writer</span> <span class="n">writer</span> <span class="o">=</span>
      <span class="n">responder</span><span class="o">.</span><span class="na">stream</span><span class="o">(</span><span class="k">new</span> <span class="n">ProcedureResponse</span><span class="o">(</span><span class="n">SUCCESS</span><span class="o">));</span>
    <span class="n">writer</span><span class="o">.</span><span class="na">write</span><span class="o">(</span><span class="n">ByteBuffer</span><span class="o">.</span><span class="na">wrap</span><span class="o">(</span><span class="n">hello</span><span class="o">.</span><span class="na">getBytes</span><span class="o">())).</span><span class="na">close</span><span class="o">();</span>
  <span class="o">}</span>
<span class="o">}</span>
</pre></div>
</div>
<p>This uses the most generic way to create the response, which allows you
to send arbitrary byte content as the response body. In many cases, you
will actually respond with JSON. A CDAP
<tt class="docutils literal"><span class="pre">ProcedureResponder</span></tt> has convenience methods for returning JSON maps:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="c1">// Return a JSON map</span>
<span class="n">Map</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Object</span><span class="o">&gt;</span> <span class="n">results</span> <span class="o">=</span> <span class="k">new</span> <span class="n">TreeMap</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Object</span><span class="o">&gt;();</span>
<span class="n">results</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&quot;totalWords&quot;</span><span class="o">,</span> <span class="n">totalWords</span><span class="o">);</span>
<span class="n">results</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&quot;uniqueWords&quot;</span><span class="o">,</span> <span class="n">uniqueWords</span><span class="o">);</span>
<span class="n">results</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&quot;averageLength&quot;</span><span class="o">,</span> <span class="n">averageLength</span><span class="o">);</span>
<span class="n">responder</span><span class="o">.</span><span class="na">sendJson</span><span class="o">(</span><span class="n">results</span><span class="o">);</span>
</pre></div>
</div>
<p>There is also a convenience method to respond with an error message:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="nd">@Handle</span><span class="o">(</span><span class="s">&quot;getCount&quot;</span><span class="o">)</span>
<span class="kd">public</span> <span class="kt">void</span> <span class="nf">getCount</span><span class="o">(</span><span class="n">ProcedureRequest</span> <span class="n">request</span><span class="o">,</span> <span class="n">ProcedureResponder</span> <span class="n">responder</span><span class="o">)</span>
                     <span class="kd">throws</span> <span class="n">IOException</span><span class="o">,</span> <span class="n">InterruptedException</span> <span class="o">{</span>
  <span class="n">String</span> <span class="n">word</span> <span class="o">=</span> <span class="n">request</span><span class="o">.</span><span class="na">getArgument</span><span class="o">(</span><span class="s">&quot;word&quot;</span><span class="o">);</span>
  <span class="k">if</span> <span class="o">(</span><span class="n">word</span> <span class="o">==</span> <span class="kc">null</span><span class="o">)</span> <span class="o">{</span>
    <span class="n">responder</span><span class="o">.</span><span class="na">error</span><span class="o">(</span><span class="n">Code</span><span class="o">.</span><span class="na">CLIENT_ERROR</span><span class="o">,</span>
                    <span class="s">&quot;Method &#39;getCount&#39; requires argument &#39;word&#39;&quot;</span><span class="o">);</span>
    <span class="k">return</span><span class="o">;</span>
  <span class="o">}</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="transaction-system">
<span id="id10"></span><h2>Transaction System<a class="headerlink" href="#transaction-system" title="Permalink to this headline">¶</a></h2>
<div class="section" id="the-need-for-transactions">
<h3>The Need for Transactions<a class="headerlink" href="#the-need-for-transactions" title="Permalink to this headline">¶</a></h3>
<p>A Flowlet processes the data objects received on its inputs one at a time. While processing
a single input object, all operations, including the removal of the data from the input,
and emission of data to the outputs, are executed in a <strong>transaction</strong>. This provides us
with ACID—atomicity, consistency, isolation, and durability properties:</p>
<ul class="simple">
<li>The process method runs under read isolation to ensure that it does not see dirty writes
(uncommitted writes from concurrent processing) in any of its reads.
It does see, however, its own writes.</li>
<li>A failed attempt to process an input object leaves the data in a consistent state;
it does not leave partial writes behind.</li>
<li>All writes and emission of data are committed atomically;
either all of them or none of them are persisted.</li>
<li>After processing completes successfully, all its writes are persisted in a durable way.</li>
</ul>
<p>In case of failure, the state of the data is unchanged and processing of the input
object can be reattempted. This ensures &#8220;exactly-once&#8221; processing of each object.</p>
</div>
<div class="section" id="occ-optimistic-concurrency-control">
<h3>OCC: Optimistic Concurrency Control<a class="headerlink" href="#occ-optimistic-concurrency-control" title="Permalink to this headline">¶</a></h3>
<p>The Cask Data Application Platform uses <em>Optimistic Concurrency Control</em> (OCC) to implement
transactions. Unlike most relational databases that use locks to prevent conflicting
operations between transactions, under OCC we allow these conflicting writes to happen.
When the transaction is committed, we can detect whether it has any conflicts: namely, if
during the lifetime of the transaction, another transaction committed a write for one of
the same keys that the transaction has written. In that case, the transaction is aborted
and all of its writes are rolled back.</p>
<p>In other words: If two overlapping transactions modify the same row, then the transaction
that commits first will succeed, but the transaction that commits last is rolled back due
to a write conflict.</p>
<p>Optimistic Concurrency Control is lockless and therefore avoids problems such as idle
processes waiting for locks, or even worse, deadlocks. However, it comes at the cost of
rollback in case of write conflicts. We can only achieve high throughput with OCC if the
number of conflicts is small. It is therefore good practice to reduce the probability of
conflicts wherever possible.</p>
<p>Here are some rules to follow for Flows, Flowlets, Services, and Procedures:</p>
<ul class="simple">
<li>Keep transactions short. The Cask Data Application Platform attempts to delay the beginning of each
transaction as long as possible. For instance, if your Flowlet only performs write
operations, but no read operations, then all writes are deferred until the process
method returns. They are then performed and transacted, together with the
removal of the processed object from the input, in a single batch execution.
This minimizes the duration of the transaction.</li>
<li>However, if your Flowlet performs a read, then the transaction must
begin at the time of the read. If your Flowlet performs long-running
computations after that read, then the transaction runs longer, too,
and the risk of conflicts increases. It is therefore good practice
to perform reads as late in the process method as possible.</li>
<li>There are two ways to perform an increment: As a write operation that
returns nothing, or as a read-write operation that returns the incremented
value. If you perform the read-write operation, then that forces the
transaction to begin, and the chance of conflict increases. Unless you
depend on that return value, you should always perform an increment
only as a write operation.</li>
<li>Use hash-based partitioning for the inputs of highly concurrent Flowlets
that perform writes. This helps reduce concurrent writes to the same
key from different instances of the Flowlet.</li>
</ul>
<p>Keeping these guidelines in mind will help you write more efficient and faster-performing
code.</p>
</div>
<div class="section" id="the-need-for-disabling-transactions">
<h3>The Need for Disabling Transactions<a class="headerlink" href="#the-need-for-disabling-transactions" title="Permalink to this headline">¶</a></h3>
<p>Transactions providing ACID (atomicity, consistency, isolation, and durability) guarantees
are useful in several applications where data accuracy is critical—examples include billing
applications and computing click-through rates.</p>
<p>However, some applications—such as trending—might not need it. Applications that do not
strictly require accuracy can trade off accuracy against increased throughput by taking
advantage of not having to write/read all the data in a transaction.</p>
</div>
<div class="section" id="disabling-transactions">
<h3>Disabling Transactions<a class="headerlink" href="#disabling-transactions" title="Permalink to this headline">¶</a></h3>
<p>Transactions can be disabled for a Flow by annotating the Flow class with the
<tt class="docutils literal"><span class="pre">&#64;DisableTransaction</span></tt> annotation:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="nd">@DisableTransaction</span>
<span class="kd">class</span> <span class="nc">MyExampleFlow</span> <span class="kd">implements</span> <span class="n">Flow</span> <span class="o">{</span>
  <span class="o">...</span>
<span class="o">}</span>
</pre></div>
</div>
<p>While this may speed up performance, if—for example—a Flowlet fails, the system would not
be able to roll back to its previous state. You will need to judge whether the increase in
performance offsets the increased risk of inaccurate data.</p>
</div>
<div class="section" id="transactions-in-mapreduce">
<h3>Transactions in MapReduce<a class="headerlink" href="#transactions-in-mapreduce" title="Permalink to this headline">¶</a></h3>
<p>When you run a MapReduce job that interacts with Datasets, the system creates a
long-running transaction. Similar to the transaction of a Flowlet or a Procedure, here are
some rules to follow:</p>
<ul class="simple">
<li>Reads can only see the writes of other transactions that were committed
at the time the long-running transaction was started.</li>
<li>All writes of the long-running transaction are committed atomically,
and only become visible to others after they are committed.</li>
<li>The long-running transaction can read its own writes.</li>
</ul>
<p>However, there is a key difference: long-running transactions do not participate in
conflict detection. If another transaction overlaps with the long-running transaction and
writes to the same row, it will not cause a conflict but simply overwrite it.</p>
<p>It is not efficient to fail the long-running job based on a single conflict. Because of
this, it is not recommended to write to the same Dataset from both real-time and MapReduce
programs. It is better to use different Datasets, or at least ensure that the real-time
processing writes to a disjoint set of columns.</p>
<p>It&#8217;s important to note that the MapReduce framework will reattempt a task (Mapper or
Reducer) if it fails. If the task is writing to a Dataset, the reattempt of the task will
most likely repeat the writes that were already performed in the failed attempt. Therefore
it is highly advisable that all writes performed by MapReduce programs be idempotent.</p>
</div>
</div>
<div class="section" id="best-practices-for-developing-applications">
<h2>Best Practices for Developing Applications<a class="headerlink" href="#best-practices-for-developing-applications" title="Permalink to this headline">¶</a></h2>
<div class="section" id="initializing-instance-fields">
<h3>Initializing Instance Fields<a class="headerlink" href="#initializing-instance-fields" title="Permalink to this headline">¶</a></h3>
<p>There are three ways to initialize instance fields used in Flowlets and Procedures:</p>
<ol class="arabic simple">
<li>Using the default constructor;</li>
<li>Using the <tt class="docutils literal"><span class="pre">initialize()</span></tt> method of the Flowlets and Procedures; and</li>
<li>Using <tt class="docutils literal"><span class="pre">&#64;Property</span></tt> annotations.</li>
</ol>
<p>To initialize using an Property annotation, simply annotate the field definition with
<tt class="docutils literal"><span class="pre">&#64;Property</span></tt>.</p>
<p>The following example demonstrates the convenience of using <tt class="docutils literal"><span class="pre">&#64;Property</span></tt> in a
<tt class="docutils literal"><span class="pre">WordFilter</span></tt> flowlet
that filters out specific words:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="kd">public</span> <span class="kd">static</span> <span class="kd">class</span> <span class="nc">WordFilter</span> <span class="kd">extends</span> <span class="n">AbstractFlowlet</span> <span class="o">{</span>

  <span class="kd">private</span> <span class="n">OutputEmitter</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;</span> <span class="n">out</span><span class="o">;</span>

  <span class="nd">@Property</span>
  <span class="kd">private</span> <span class="kd">final</span> <span class="n">String</span> <span class="n">toFilterOut</span><span class="o">;</span>

  <span class="kd">public</span> <span class="nf">CountByField</span><span class="o">(</span><span class="n">String</span> <span class="n">toFilterOut</span><span class="o">)</span> <span class="o">{</span>
    <span class="k">this</span><span class="o">.</span><span class="na">toFilterOut</span> <span class="o">=</span> <span class="n">toFilterOut</span><span class="o">;</span>
  <span class="o">}</span>

  <span class="nd">@ProcessInput</span><span class="o">()</span>
  <span class="kd">public</span> <span class="kt">void</span> <span class="nf">process</span><span class="o">(</span><span class="n">String</span> <span class="n">word</span><span class="o">)</span> <span class="o">{</span>
    <span class="k">if</span> <span class="o">(!</span><span class="n">toFilterOut</span><span class="o">.</span><span class="na">equals</span><span class="o">(</span><span class="n">word</span><span class="o">))</span> <span class="o">{</span>
      <span class="n">out</span><span class="o">.</span><span class="na">emit</span><span class="o">(</span><span class="n">word</span><span class="o">);</span>
    <span class="o">}</span>
  <span class="o">}</span>
<span class="o">}</span>
</pre></div>
</div>
<p>The Flowlet constructor is called with the parameter when the Flow is configured:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="kd">public</span> <span class="kd">static</span> <span class="kd">class</span> <span class="nc">WordCountFlow</span> <span class="kd">implements</span> <span class="n">Flow</span> <span class="o">{</span>
  <span class="nd">@Override</span>
  <span class="kd">public</span> <span class="n">FlowSpecification</span> <span class="nf">configure</span><span class="o">()</span> <span class="o">{</span>
    <span class="k">return</span> <span class="n">FlowSpecification</span><span class="o">.</span><span class="na">Builder</span><span class="o">.</span><span class="na">with</span><span class="o">()</span>
      <span class="o">.</span><span class="na">setName</span><span class="o">(</span><span class="s">&quot;WordCountFlow&quot;</span><span class="o">)</span>
      <span class="o">.</span><span class="na">setDescription</span><span class="o">(</span><span class="s">&quot;Flow for counting words&quot;</span><span class="o">)</span>
      <span class="o">.</span><span class="na">withFlowlets</span><span class="o">().</span><span class="na">add</span><span class="o">(</span><span class="k">new</span> <span class="n">Tokenizer</span><span class="o">())</span>
                     <span class="o">.</span><span class="na">add</span><span class="o">(</span><span class="k">new</span> <span class="n">WordsFilter</span><span class="o">(</span><span class="s">&quot;the&quot;</span><span class="o">))</span>
                     <span class="o">.</span><span class="na">add</span><span class="o">(</span><span class="k">new</span> <span class="n">WordsCounter</span><span class="o">())</span>
      <span class="o">.</span><span class="na">connect</span><span class="o">().</span><span class="na">fromStream</span><span class="o">(</span><span class="s">&quot;text&quot;</span><span class="o">).</span><span class="na">to</span><span class="o">(</span><span class="s">&quot;Tokenizer&quot;</span><span class="o">)</span>
                <span class="o">.</span><span class="na">from</span><span class="o">(</span><span class="s">&quot;Tokenizer&quot;</span><span class="o">).</span><span class="na">to</span><span class="o">(</span><span class="s">&quot;WordsFilter&quot;</span><span class="o">)</span>
                <span class="o">.</span><span class="na">from</span><span class="o">(</span><span class="s">&quot;WordsFilter&quot;</span><span class="o">).</span><span class="na">to</span><span class="o">(</span><span class="s">&quot;WordsCounter&quot;</span><span class="o">)</span>
      <span class="o">.</span><span class="na">build</span><span class="o">();</span>
  <span class="o">}</span>
<span class="o">}</span>
</pre></div>
</div>
<p>At run-time, when the Flowlet is started, a value is injected into the <tt class="docutils literal"><span class="pre">toFilterOut</span></tt>
field.</p>
<p>Field types that are supported using the <tt class="docutils literal"><span class="pre">&#64;Property</span></tt> annotation are primitives,
boxed types (e.g. <tt class="docutils literal"><span class="pre">Integer</span></tt>), <tt class="docutils literal"><span class="pre">String</span></tt> and <tt class="docutils literal"><span class="pre">enum</span></tt>.</p>
</div>
</div>
<div class="section" id="where-to-go-next">
<h2>Where to Go Next<a class="headerlink" href="#where-to-go-next" title="Permalink to this headline">¶</a></h2>
<p>Now that you&#8217;ve had an introduction to programming applications
for CDAP, take a look at:</p>
<ul class="simple">
<li><a class="reference internal" href="apps-packs.html"><em>Apps and Packs</em></a>, to walk through some example applications and useful datasets.</li>
</ul>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper"><!--
  Copyright © 2014 Cask Data, Inc.

  Licensed under the Apache License, Version 2.0 (the "License"); you may not
  use this file except in compliance with the License. You may obtain a copy of
  the License at

  http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
  WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
  License for the specific language governing permissions and limitations under
  the License.
-->

<h3><a href="index.html">Table of Contents</a></h3>
<nav>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="intro.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="getstarted.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="case_study.html">Case Study</a></li>
<li class="toctree-l1"><a class="reference internal" href="arch.html">Concepts and Architecture</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="">Developer Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#introduction">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="#data-virtualization">Data Virtualization</a></li>
<li class="toctree-l2"><a class="reference internal" href="#streams">Streams</a></li>
<li class="toctree-l2"><a class="reference internal" href="#datasets">Datasets</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#types-of-datasets">Types of Datasets</a></li>
<li class="toctree-l3"><a class="reference internal" href="#core-datasets">Core Datasets</a></li>
<li class="toctree-l3"><a class="reference internal" href="#table-api">Table API</a></li>
<li class="toctree-l3"><a class="reference internal" href="#system-datasets">System Datasets</a></li>
<li class="toctree-l3"><a class="reference internal" href="#custom-datasets">Custom Datasets</a></li>
<li class="toctree-l3"><a class="reference internal" href="#datasets-and-mapreduce">Datasets and MapReduce</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#data-exploration">Data Exploration</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#defining-the-record-schema">Defining the Record Schema</a></li>
<li class="toctree-l3"><a class="reference internal" href="#limitations">Limitations</a></li>
<li class="toctree-l3"><a class="reference internal" href="#parameterized-types">Parameterized Types</a></li>
<li class="toctree-l3"><a class="reference internal" href="#complex-types">Complex Types</a></li>
<li class="toctree-l3"><a class="reference internal" href="#scanning-records">Scanning Records</a></li>
<li class="toctree-l3"><a class="reference internal" href="#writing-to-datasets-with-sql">Writing to Datasets with SQL</a></li>
<li class="toctree-l3"><a class="reference internal" href="#connecting-to-cdap-datasets-using-cdap-jdbc-driver">Connecting to CDAP Datasets using CDAP JDBC driver</a></li>
<li class="toctree-l3"><a class="reference internal" href="#formulating-queries">Formulating Queries</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#application-virtualization">Application Virtualization</a></li>
<li class="toctree-l2"><a class="reference internal" href="#applications">Applications</a></li>
<li class="toctree-l2"><a class="reference internal" href="#flows">Flows</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#flowlets">Flowlets</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#mapreduce">MapReduce</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#mapreduce-and-datasets">MapReduce and Datasets</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#workflow">Workflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="#spark-beta-standalone-cdap-only">Spark (Beta, Standalone CDAP only)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#cdap-sparkcontext">CDAP SparkContext</a></li>
<li class="toctree-l3"><a class="reference internal" href="#spark-and-datasets">Spark and Datasets</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#services">Services</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#service-handlers">Service Handlers</a></li>
<li class="toctree-l3"><a class="reference internal" href="#service-discovery">Service Discovery</a></li>
<li class="toctree-l3"><a class="reference internal" href="#procedures">Procedures</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#transaction-system">Transaction System</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#the-need-for-transactions">The Need for Transactions</a></li>
<li class="toctree-l3"><a class="reference internal" href="#occ-optimistic-concurrency-control">OCC: Optimistic Concurrency Control</a></li>
<li class="toctree-l3"><a class="reference internal" href="#the-need-for-disabling-transactions">The Need for Disabling Transactions</a></li>
<li class="toctree-l3"><a class="reference internal" href="#disabling-transactions">Disabling Transactions</a></li>
<li class="toctree-l3"><a class="reference internal" href="#transactions-in-mapreduce">Transactions in MapReduce</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#best-practices-for-developing-applications">Best Practices for Developing Applications</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#initializing-instance-fields">Initializing Instance Fields</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#where-to-go-next">Where to Go Next</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="apps-packs.html">Apps and Packs</a></li>
<li class="toctree-l1"><a class="reference internal" href="api.html">APIs and Clients</a></li>
<li class="toctree-l1"><a class="reference internal" href="javadocs/index.html">Javadocs</a></li>
<li class="toctree-l1"><a class="reference internal" href="tools.html">Tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="admin.html">Administration and Operations</a></li>
<li class="toctree-l1"><a class="reference internal" href="licenses/index.html">Licenses and Dependencies</a></li>
<li class="toctree-l1"><a class="reference internal" href="releasenotes.html">Release Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq/index.html">FAQ</a></li>
</ul>

</nav>
  <h4>Previous Topic</h4>
  <p class="topless"><a href="arch.html"
                        title="Previous Chapter">Cask Data Application Platform Concepts and Architecture</a></p>
  <h4>Next Topic</h4>
  <p class="topless"><a href="apps-packs.html"
                        title="Next Chapter">Cask Data Application Platform Applications and Packs</a></p>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick Search</h3>
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >Index</a></li>
        <li class="right" >
          <a href="apps-packs.html" title="Cask Data Application Platform Applications and Packs"
             >Next</a> |</li>
        <li class="right" >
          <a href="arch.html" title="Cask Data Application Platform Concepts and Architecture"
             >Previous</a> |</li>
        <li><a href="index.html">Cask Data Application Platform 2.5.0 Documentation</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &copy; Copyright 2014 Cask Data, Inc.
    </div>
  </body>
</html>